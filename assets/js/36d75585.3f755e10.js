"use strict";(globalThis.webpackChunkbook_website=globalThis.webpackChunkbook_website||[]).push([[2872],{5149:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2/unity-robotics","title":"Unity for Robotics","description":"Using Unity for robotics simulation: photorealistic rendering, synthetic data, and ROS 2 integration.","source":"@site/docs/module-2/unity-robotics.md","sourceDirName":"module-2","slug":"/module-2/unity-robotics","permalink":"/physical-ai-robotics-book/docs/module-2/unity-robotics","draft":false,"unlisted":false,"editUrl":"https://github.com/fun33333/physical-ai-robotics-book/tree/main/book-website/docs/module-2/unity-robotics.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"title":"Unity for Robotics","sidebar_position":5,"description":"Using Unity for robotics simulation: photorealistic rendering, synthetic data, and ROS 2 integration."},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo-ROS 2 Integration","permalink":"/physical-ai-robotics-book/docs/module-2/gazebo-ros2-integration"},"next":{"title":"Digital Twin Workflows","permalink":"/physical-ai-robotics-book/docs/module-2/digital-twin-workflows"}}');var s=i(4848),r=i(8453);const o={title:"Unity for Robotics",sidebar_position:5,description:"Using Unity for robotics simulation: photorealistic rendering, synthetic data, and ROS 2 integration."},a="Unity for Robotics",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Why Unity for Robotics?",id:"why-unity-for-robotics",level:2},{value:"Comparison with Gazebo",id:"comparison-with-gazebo",level:3},{value:"When to Use Unity",id:"when-to-use-unity",level:3},{value:"Setting Up Unity for Robotics",id:"setting-up-unity-for-robotics",level:2},{value:"Installing Unity Hub",id:"installing-unity-hub",level:3},{value:"Recommended Unity Version",id:"recommended-unity-version",level:3},{value:"Installing Robotics Packages",id:"installing-robotics-packages",level:3},{value:"Importing Robot Models",id:"importing-robot-models",level:2},{value:"URDF Import Process",id:"urdf-import-process",level:3},{value:"Step-by-Step Import",id:"step-by-step-import",level:3},{value:"Articulation Bodies",id:"articulation-bodies",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"ROS TCP Connector Architecture",id:"ros-tcp-connector-architecture",level:3},{value:"Setting Up ROS TCP Endpoint",id:"setting-up-ros-tcp-endpoint",level:3},{value:"Unity-Side Configuration",id:"unity-side-configuration",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Unity Perception Package",id:"unity-perception-package",level:3},{value:"Domain Randomization Setup",id:"domain-randomization-setup",level:3},{value:"Dataset Export",id:"dataset-export",level:3},{value:"Simulating Sensors",id:"simulating-sensors",level:2},{value:"Camera Sensor",id:"camera-sensor",level:3},{value:"LiDAR Sensor",id:"lidar-sensor",level:3},{value:"Exercise 1: Import a Robot to Unity",id:"exercise-1-import-a-robot-to-unity",level:2},{value:"Exercise 2: ROS 2 Connection",id:"exercise-2-ros-2-connection",level:2},{value:"Exercise 3: Synthetic Dataset Generation",id:"exercise-3-synthetic-dataset-generation",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Sim-to-Real Tips",id:"sim-to-real-tips",level:3},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"unity-for-robotics",children:"Unity for Robotics"})}),"\n",(0,s.jsx)(e.p,{children:"Unity brings game engine technology to robotics, offering photorealistic rendering, efficient synthetic data generation, and a massive ecosystem of assets and tools. This chapter introduces Unity for robotics applications, focusing on perception training and ROS 2 integration."}),"\n",(0,s.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(e.p,{children:"In this section, you will:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Set up Unity for robotics development with the Robotics Hub"}),"\n",(0,s.jsx)(e.li,{children:"Import and configure robot models (URDF to Unity)"}),"\n",(0,s.jsx)(e.li,{children:"Configure articulation bodies for physics simulation"}),"\n",(0,s.jsx)(e.li,{children:"Generate synthetic datasets for perception training"}),"\n",(0,s.jsx)(e.li,{children:"Integrate Unity with ROS 2 via TCP connector"}),"\n",(0,s.jsx)(e.li,{children:"Create domain randomization pipelines for robust AI"}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(e.p,{children:"Before starting, ensure you have:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.a,{href:"/docs/module-2/gazebo-basics",children:"Gazebo Basics"})," completed"]}),"\n",(0,s.jsx)(e.li,{children:"Ubuntu 22.04 or Windows 10/11"}),"\n",(0,s.jsx)(e.li,{children:"NVIDIA GPU with 4GB+ VRAM (recommended)"}),"\n",(0,s.jsx)(e.li,{children:"Unity Hub installed"}),"\n",(0,s.jsx)(e.li,{children:"Basic understanding of 3D graphics concepts"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"why-unity-for-robotics",children:"Why Unity for Robotics?"}),"\n",(0,s.jsx)(e.h3,{id:"comparison-with-gazebo",children:"Comparison with Gazebo"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Feature"}),(0,s.jsx)(e.th,{children:"Gazebo"}),(0,s.jsx)(e.th,{children:"Unity"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Physics accuracy"}),(0,s.jsx)(e.td,{children:"High"}),(0,s.jsx)(e.td,{children:"Medium-High"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Visual quality"}),(0,s.jsx)(e.td,{children:"Medium"}),(0,s.jsx)(e.td,{children:"Photorealistic"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"ROS integration"}),(0,s.jsx)(e.td,{children:"Native"}),(0,s.jsx)(e.td,{children:"Via connector"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Asset ecosystem"}),(0,s.jsx)(e.td,{children:"Robotics-focused"}),(0,s.jsx)(e.td,{children:"Massive marketplace"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Synthetic data"}),(0,s.jsx)(e.td,{children:"Basic"}),(0,s.jsx)(e.td,{children:"Excellent"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Learning curve"}),(0,s.jsx)(e.td,{children:"Moderate"}),(0,s.jsx)(e.td,{children:"Steeper"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Cost"}),(0,s.jsx)(e.td,{children:"Free (OSS)"}),(0,s.jsx)(e.td,{children:"Free tier available"})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"when-to-use-unity",children:"When to Use Unity"}),"\n",(0,s.jsx)(e.p,{children:"Unity excels for:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Perception training"}),": Generate synthetic images for object detection, segmentation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Synthetic data at scale"}),": Domain randomization for robust models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Visualization"}),": Create compelling demos and presentations"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Cross-platform deployment"}),": Build for VR, mobile, web"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Custom environments"}),": Leverage asset store for diverse scenes"]}),"\n"]}),"\n",(0,s.jsx)(e.admonition,{title:"Best Practice",type:"info",children:(0,s.jsx)(e.p,{children:"Use Gazebo for control and navigation development, Unity for perception and synthetic data generation. Many teams use both in their pipeline."})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"setting-up-unity-for-robotics",children:"Setting Up Unity for Robotics"}),"\n",(0,s.jsx)(e.h3,{id:"installing-unity-hub",children:"Installing Unity Hub"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",metastring:'title="Install Unity Hub on Ubuntu"',children:"# Add Unity repository\nwget -qO - https://hub.unity3d.com/linux/keys/public | sudo apt-key add -\nsudo sh -c 'echo \"deb https://hub.unity3d.com/linux/repos/deb stable main\" > /etc/apt/sources.list.d/unityhub.list'\n\n# Install Unity Hub\nsudo apt update\nsudo apt install unityhub\n\n# Launch Unity Hub\nunityhub\n"})}),"\n",(0,s.jsx)(e.h3,{id:"recommended-unity-version",children:"Recommended Unity Version"}),"\n",(0,s.jsxs)(e.p,{children:["For robotics simulation, use Unity ",(0,s.jsx)(e.strong,{children:"2022.3 LTS"})," or later:"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Open Unity Hub"}),"\n",(0,s.jsx)(e.li,{children:'Click "Installs" \u2192 "Install Editor"'}),"\n",(0,s.jsx)(e.li,{children:"Select 2022.3.x LTS"}),"\n",(0,s.jsxs)(e.li,{children:["Add modules:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Linux Build Support (if on Windows/Mac)"}),"\n",(0,s.jsx)(e.li,{children:"Visual Studio / VS Code integration"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"installing-robotics-packages",children:"Installing Robotics Packages"}),"\n",(0,s.jsx)(e.p,{children:"Create a new 3D project, then add packages:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Open ",(0,s.jsx)(e.strong,{children:"Window \u2192 Package Manager"})]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"+ \u2192 Add package from git URL"})]}),"\n",(0,s.jsx)(e.li,{children:"Add these packages:"}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-text",children:"# Unity Robotics Hub\nhttps://github.com/Unity-Technologies/Unity-Robotics-Hub.git?path=/com.unity.robotics.ros-tcp-connector\n\n# URDF Importer\nhttps://github.com/Unity-Technologies/URDF-Importer.git?path=/com.unity.robotics.urdf-importer\n\n# Perception (for synthetic data)\ncom.unity.perception\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,s.jsx)(e.h3,{id:"urdf-import-process",children:"URDF Import Process"}),"\n",(0,s.jsx)(e.p,{children:"Unity's URDF Importer converts URDF files to Unity GameObjects with ArticulationBodies:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    URDF Import Pipeline                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502   \u2502  URDF    \u2502     \u2502  Parse   \u2502     \u2502   Unity          \u2502       \u2502\n\u2502   \u2502  File    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Links   \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   GameObject     \u2502       \u2502\n\u2502   \u2502  (.urdf) \u2502     \u2502  Joints  \u2502     \u2502   Hierarchy      \u2502       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502        \u2502                                     \u2502                  \u2502\n\u2502        \u2502           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502                  \u2502\n\u2502        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502    Meshes    \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2502                    \u2502  Colliders   \u2502                             \u2502\n\u2502                    \u2502  Materials   \u2502                             \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                             \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(e.h3,{id:"step-by-step-import",children:"Step-by-Step Import"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Prepare your URDF"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Ensure all mesh paths are relative"}),"\n",(0,s.jsxs)(e.li,{children:["Include ",(0,s.jsx)(e.code,{children:"<visual>"}),", ",(0,s.jsx)(e.code,{children:"<collision>"}),", and ",(0,s.jsx)(e.code,{children:"<inertial>"})," tags"]}),"\n",(0,s.jsx)(e.li,{children:"Package meshes with the URDF file"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Import in Unity"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Assets \u2192 Import Robot from URDF\n"})}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Configure import settings"}),":"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="URDF Import Settings (Editor)"',children:"// Access via Import Robot dialog\npublic class URDFImportSettings\n{\n    // Physics settings\n    public bool useArticulationBodies = true;  // Recommended for robots\n    public float defaultMass = 1.0f;           // For links without mass\n\n    // Visual settings\n    public bool importVisuals = true;\n    public bool importCollisions = true;\n\n    // Joint settings\n    public float stiffness = 10000f;\n    public float damping = 100f;\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"articulation-bodies",children:"Articulation Bodies"}),"\n",(0,s.jsx)(e.p,{children:"Unity uses ArticulationBodies for robot physics - a system designed for robotics:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="ArticulationBody Configuration"',children:"using UnityEngine;\n\npublic class RobotJointController : MonoBehaviour\n{\n    private ArticulationBody[] joints;\n\n    void Start()\n    {\n        // Get all articulation bodies in hierarchy\n        joints = GetComponentsInChildren<ArticulationBody>();\n\n        foreach (var joint in joints)\n        {\n            // Configure joint drives for position control\n            var drive = joint.xDrive;\n            drive.stiffness = 10000f;  // Position gain\n            drive.damping = 100f;       // Velocity damping\n            drive.forceLimit = 1000f;   // Max torque\n            joint.xDrive = drive;\n        }\n    }\n\n    public void SetJointTarget(int jointIndex, float targetPosition)\n    {\n        if (jointIndex < joints.Length)\n        {\n            var drive = joints[jointIndex].xDrive;\n            drive.target = targetPosition * Mathf.Rad2Deg;  // Convert to degrees\n            joints[jointIndex].xDrive = drive;\n        }\n    }\n}\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,s.jsx)(e.h3,{id:"ros-tcp-connector-architecture",children:"ROS TCP Connector Architecture"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Unity-ROS 2 Communication                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502   \u2502    Unity     \u2502     TCP/IP         \u2502    ROS 2     \u2502          \u2502\n\u2502   \u2502  Simulation  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502    Nodes     \u2502          \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502          \u2502                                   \u2502                   \u2502\n\u2502          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502                   \u2502\n\u2502          \u2514\u2500\u2500\u2502   ROS TCP Connector     \u2502\u2500\u2500\u2500\u2500\u2500\u2518                   \u2502\n\u2502             \u2502   (Unity Package)       \u2502                         \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                        \u2502                                         \u2502\n\u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502             \u2502  ROS TCP Endpoint       \u2502                         \u2502\n\u2502             \u2502  (ROS 2 Node)           \u2502                         \u2502\n\u2502             \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(e.h3,{id:"setting-up-ros-tcp-endpoint",children:"Setting Up ROS TCP Endpoint"}),"\n",(0,s.jsx)(e.p,{children:"On your ROS 2 machine:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",metastring:'title="Install and run ROS TCP Endpoint"',children:"# Install the ROS TCP Endpoint package\ncd ~/ros2_ws/src\ngit clone -b main https://github.com/Unity-Technologies/ROS-TCP-Endpoint.git\n\n# Build\ncd ~/ros2_ws\ncolcon build --packages-select ros_tcp_endpoint\n\n# Source and run\nsource install/setup.bash\nros2 run ros_tcp_endpoint default_server_endpoint --ros-args -p ROS_IP:=0.0.0.0\n"})}),"\n",(0,s.jsx)(e.h3,{id:"unity-side-configuration",children:"Unity-Side Configuration"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="ROSConnection Setup"',children:'using Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Geometry;\nusing RosMessageTypes.Sensor;\n\npublic class ROS2Interface : MonoBehaviour\n{\n    private ROSConnection ros;\n\n    void Start()\n    {\n        // Get ROSConnection instance\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.ConnectOnStart = true;\n\n        // Configure connection (also settable in Inspector)\n        // ROS IP: 127.0.0.1 (or your ROS machine IP)\n        // ROS Port: 10000\n\n        // Register publishers\n        ros.RegisterPublisher<TwistMsg>("/cmd_vel");\n        ros.RegisterPublisher<ImageMsg>("/camera/image_raw");\n\n        // Register subscribers\n        ros.Subscribe<LaserScanMsg>("/scan", OnLaserScan);\n        ros.Subscribe<JointStateMsg>("/joint_states", OnJointStates);\n    }\n\n    void OnLaserScan(LaserScanMsg msg)\n    {\n        // Process incoming LiDAR data\n        Debug.Log($"Received {msg.ranges.Length} range readings");\n    }\n\n    void OnJointStates(JointStateMsg msg)\n    {\n        // Update robot visualization\n        for (int i = 0; i < msg.name.Length; i++)\n        {\n            Debug.Log($"Joint {msg.name[i]}: {msg.position[i]}");\n        }\n    }\n\n    public void PublishCmdVel(float linear, float angular)\n    {\n        var msg = new TwistMsg\n        {\n            linear = new Vector3Msg { x = linear },\n            angular = new Vector3Msg { z = angular }\n        };\n        ros.Publish("/cmd_vel", msg);\n    }\n}\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,s.jsx)(e.h3,{id:"unity-perception-package",children:"Unity Perception Package"}),"\n",(0,s.jsx)(e.p,{children:"The Perception package enables large-scale synthetic data generation:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="Setting up Perception Camera"',children:"using UnityEngine;\nusing UnityEngine.Perception.GroundTruth;\nusing UnityEngine.Perception.Randomization.Scenarios;\n\npublic class SyntheticDataCamera : MonoBehaviour\n{\n    void Start()\n    {\n        // Add Perception Camera component\n        var perceptionCamera = gameObject.AddComponent<PerceptionCamera>();\n\n        // Configure labelers for different annotations\n        // - Bounding Box 2D: Object detection\n        // - Semantic Segmentation: Pixel-wise labels\n        // - Instance Segmentation: Per-object masks\n        // - Keypoint: Pose estimation\n    }\n}\n"})}),"\n",(0,s.jsx)(e.h3,{id:"domain-randomization-setup",children:"Domain Randomization Setup"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="RandomizerConfiguration.cs"',children:'using UnityEngine;\nusing UnityEngine.Perception.Randomization.Randomizers;\nusing UnityEngine.Perception.Randomization.Parameters;\n\n// Randomize lighting conditions\n[AddRandomizerMenu("Perception/Light Randomizer")]\npublic class LightRandomizer : Randomizer\n{\n    public FloatParameter intensity = new FloatParameter { value = new UniformSampler(0.5f, 2.0f) };\n    public ColorHsvaParameter color = new ColorHsvaParameter();\n\n    protected override void OnIterationStart()\n    {\n        var lights = tagManager.Query<LightRandomizerTag>();\n        foreach (var light in lights)\n        {\n            var l = light.GetComponent<Light>();\n            l.intensity = intensity.Sample();\n            l.color = color.Sample();\n        }\n    }\n}\n\n// Randomize object positions\n[AddRandomizerMenu("Perception/Pose Randomizer")]\npublic class PoseRandomizer : Randomizer\n{\n    public Vector3Parameter position = new Vector3Parameter();\n    public Vector3Parameter rotation = new Vector3Parameter();\n\n    protected override void OnIterationStart()\n    {\n        var objects = tagManager.Query<PoseRandomizerTag>();\n        foreach (var obj in objects)\n        {\n            obj.transform.position = position.Sample();\n            obj.transform.eulerAngles = rotation.Sample();\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(e.h3,{id:"dataset-export",children:"Dataset Export"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="DatasetExporter.cs"',children:"using UnityEngine;\nusing UnityEngine.Perception.GroundTruth;\n\npublic class DatasetExporter : MonoBehaviour\n{\n    // Perception package automatically exports to:\n    // Windows: %USERPROFILE%\\AppData\\LocalLow\\DefaultCompany\\ProjectName\\\n    // Linux: ~/.config/unity3d/DefaultCompany/ProjectName/\n\n    // Output formats:\n    // - COCO (object detection)\n    // - SOLO (Unity's native format)\n    // - Custom (via DatasetConsumer)\n\n    void ConfigureExport()\n    {\n        // Dataset is exported automatically during simulation\n        // Configure in Perception Camera component:\n        // - Capture trigger mode (scheduled, manual)\n        // - Frames between captures\n        // - Start frame\n    }\n}\n"})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"simulating-sensors",children:"Simulating Sensors"}),"\n",(0,s.jsx)(e.h3,{id:"camera-sensor",children:"Camera Sensor"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="CameraSensor.cs"',children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class CameraSensor : MonoBehaviour\n{\n    public Camera sensorCamera;\n    public int width = 640;\n    public int height = 480;\n    public float publishRate = 30f;\n\n    private ROSConnection ros;\n    private RenderTexture renderTexture;\n    private Texture2D texture2D;\n    private float timeSincePublish = 0f;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<ImageMsg>("/camera/image_raw");\n\n        // Create render texture\n        renderTexture = new RenderTexture(width, height, 24);\n        sensorCamera.targetTexture = renderTexture;\n        texture2D = new Texture2D(width, height, TextureFormat.RGB24, false);\n    }\n\n    void Update()\n    {\n        timeSincePublish += Time.deltaTime;\n\n        if (timeSincePublish >= 1f / publishRate)\n        {\n            PublishImage();\n            timeSincePublish = 0f;\n        }\n    }\n\n    void PublishImage()\n    {\n        // Render camera to texture\n        RenderTexture.active = renderTexture;\n        texture2D.ReadPixels(new Rect(0, 0, width, height), 0, 0);\n        texture2D.Apply();\n        RenderTexture.active = null;\n\n        // Convert to ROS message\n        var msg = new ImageMsg\n        {\n            header = new RosMessageTypes.Std.HeaderMsg\n            {\n                stamp = new RosMessageTypes.BuiltinInterfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = "camera_link"\n            },\n            width = (uint)width,\n            height = (uint)height,\n            encoding = "rgb8",\n            step = (uint)(width * 3),\n            data = texture2D.GetRawTextureData()\n        };\n\n        ros.Publish("/camera/image_raw", msg);\n    }\n}\n'})}),"\n",(0,s.jsx)(e.h3,{id:"lidar-sensor",children:"LiDAR Sensor"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-csharp",metastring:'title="LiDARSensor.cs"',children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class LiDARSensor : MonoBehaviour\n{\n    public int numRays = 360;\n    public float maxRange = 30f;\n    public float minRange = 0.1f;\n    public float publishRate = 10f;\n\n    private ROSConnection ros;\n    private float[] ranges;\n    private float timeSincePublish = 0f;\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<LaserScanMsg>("/scan");\n        ranges = new float[numRays];\n    }\n\n    void Update()\n    {\n        timeSincePublish += Time.deltaTime;\n\n        if (timeSincePublish >= 1f / publishRate)\n        {\n            ScanAndPublish();\n            timeSincePublish = 0f;\n        }\n    }\n\n    void ScanAndPublish()\n    {\n        float angleIncrement = 2 * Mathf.PI / numRays;\n\n        for (int i = 0; i < numRays; i++)\n        {\n            float angle = i * angleIncrement;\n            Vector3 direction = new Vector3(\n                Mathf.Cos(angle),\n                0,\n                Mathf.Sin(angle)\n            );\n            direction = transform.TransformDirection(direction);\n\n            RaycastHit hit;\n            if (Physics.Raycast(transform.position, direction, out hit, maxRange))\n            {\n                ranges[i] = Mathf.Max(hit.distance, minRange);\n            }\n            else\n            {\n                ranges[i] = float.PositiveInfinity;\n            }\n        }\n\n        var msg = new LaserScanMsg\n        {\n            header = new RosMessageTypes.Std.HeaderMsg\n            {\n                stamp = new RosMessageTypes.BuiltinInterfaces.TimeMsg\n                {\n                    sec = (int)Time.time,\n                    nanosec = (uint)((Time.time % 1) * 1e9)\n                },\n                frame_id = "lidar_link"\n            },\n            angle_min = 0f,\n            angle_max = 2 * Mathf.PI,\n            angle_increment = angleIncrement,\n            range_min = minRange,\n            range_max = maxRange,\n            ranges = ranges\n        };\n\n        ros.Publish("/scan", msg);\n    }\n}\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"exercise-1-import-a-robot-to-unity",children:"Exercise 1: Import a Robot to Unity"}),"\n",(0,s.jsxs)(e.admonition,{title:"Exercise 1: URDF Import and Configuration",type:"tip",children:[(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Objective"}),": Import a robot URDF into Unity and configure physics."]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Time Estimate"}),": 45 minutes"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Steps"}),":"]}),(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Create a new Unity project with 3D template"}),"\n",(0,s.jsx)(e.li,{children:"Install URDF Importer package via Package Manager"}),"\n",(0,s.jsx)(e.li,{children:"Download a robot URDF (e.g., TurtleBot3, UR5)"}),"\n",(0,s.jsx)(e.li,{children:"Import via Assets \u2192 Import Robot from URDF"}),"\n",(0,s.jsx)(e.li,{children:"Configure ArticulationBody settings for realistic physics"}),"\n",(0,s.jsx)(e.li,{children:"Add a ground plane and test that robot doesn't fall through"}),"\n"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Result"}),": Robot model visible in Unity scene with functioning joints."]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Verification"}),":"]}),(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Robot spawns above ground"}),"\n",(0,s.jsx)(e.li,{children:"Joints have correct limits"}),"\n",(0,s.jsx)(e.li,{children:"Physics simulation runs without errors"}),"\n"]})]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"exercise-2-ros-2-connection",children:"Exercise 2: ROS 2 Connection"}),"\n",(0,s.jsxs)(e.admonition,{title:"Exercise 2: Unity-ROS 2 Communication",type:"tip",children:[(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Objective"}),": Establish bidirectional communication between Unity and ROS 2."]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Time Estimate"}),": 30 minutes"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Steps"}),":"]}),(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Install ROS TCP Connector in Unity"}),"\n",(0,s.jsx)(e.li,{children:"Start ROS TCP Endpoint on ROS 2 machine"}),"\n",(0,s.jsx)(e.li,{children:"Configure ROSConnection in Unity (IP, port)"}),"\n",(0,s.jsxs)(e.li,{children:["Create a publisher for ",(0,s.jsx)(e.code,{children:"/cmd_vel"})]}),"\n",(0,s.jsxs)(e.li,{children:["Create a subscriber for ",(0,s.jsx)(e.code,{children:"/scan"})]}),"\n",(0,s.jsxs)(e.li,{children:["Test with ",(0,s.jsx)(e.code,{children:"ros2 topic echo"})," and ",(0,s.jsx)(e.code,{children:"ros2 topic pub"})]}),"\n"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Test Commands"}),":"]}),(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:'# Echo published messages from Unity\nros2 topic echo /cmd_vel\n\n# Publish test message to Unity\nros2 topic pub /scan sensor_msgs/msg/LaserScan \\\n  "{ranges: [1.0, 2.0, 3.0]}" --once\n'})}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Result"}),": Messages flow bidirectionally between Unity and ROS 2."]})]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"exercise-3-synthetic-dataset-generation",children:"Exercise 3: Synthetic Dataset Generation"}),"\n",(0,s.jsxs)(e.admonition,{title:"Exercise 3: Generate Object Detection Dataset",type:"tip",children:[(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Objective"}),": Create a synthetic dataset for training an object detection model."]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Time Estimate"}),": 60 minutes"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Steps"}),":"]}),(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Install Unity Perception package"}),"\n",(0,s.jsx)(e.li,{children:"Create a simple scene with objects to detect"}),"\n",(0,s.jsx)(e.li,{children:"Add labels to objects (via IdLabelConfig)"}),"\n",(0,s.jsx)(e.li,{children:"Configure Perception Camera with BoundingBox2D labeler"}),"\n",(0,s.jsx)(e.li,{children:"Create a Fixed Length Scenario (100 iterations)"}),"\n",(0,s.jsx)(e.li,{children:"Add randomizers for position, lighting, and camera"}),"\n",(0,s.jsx)(e.li,{children:"Run simulation and export dataset"}),"\n"]}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Configuration"}),":"]}),(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"Scenario Settings:\n- Iterations: 100\n- Frames per iteration: 1\n\nRandomizers:\n- Background: Random textures\n- Foreground: Random object positions\n- Lighting: Random intensity and color\n- Camera: Slight position variation\n"})}),(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Result"}),": 100 images with COCO-format annotations in output folder."]})]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,s.jsx)(e.h3,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,s.jsxs)(e.table,{children:[(0,s.jsx)(e.thead,{children:(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.th,{children:"Technique"}),(0,s.jsx)(e.th,{children:"Impact"}),(0,s.jsx)(e.th,{children:"When to Use"})]})}),(0,s.jsxs)(e.tbody,{children:[(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Lower resolution textures"}),(0,s.jsx)(e.td,{children:"High"}),(0,s.jsx)(e.td,{children:"Large scenes"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Reduce physics iterations"}),(0,s.jsx)(e.td,{children:"Medium"}),(0,s.jsx)(e.td,{children:"Many objects"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Batch ray casts"}),(0,s.jsx)(e.td,{children:"High"}),(0,s.jsx)(e.td,{children:"LiDAR simulation"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"GPU instancing"}),(0,s.jsx)(e.td,{children:"High"}),(0,s.jsx)(e.td,{children:"Many similar objects"})]}),(0,s.jsxs)(e.tr,{children:[(0,s.jsx)(e.td,{children:"Level of Detail (LOD)"}),(0,s.jsx)(e.td,{children:"Medium"}),(0,s.jsx)(e.td,{children:"Large environments"})]})]})]}),"\n",(0,s.jsx)(e.h3,{id:"sim-to-real-tips",children:"Sim-to-Real Tips"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Match camera intrinsics"}),": Use real camera calibration"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Add realistic noise"}),": Gaussian noise to sensors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Vary lighting extensively"}),": Real world has diverse lighting"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Include distractors"}),": Add irrelevant objects to scenes"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Test on edge cases"}),": Unusual poses, occlusions, lighting"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(e.p,{children:"In this chapter, you learned:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Unity Setup"}),": Install Unity Hub, robotics packages, and configure projects"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"URDF Import"}),": Convert robot descriptions to Unity with ArticulationBodies"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Integration"}),": Connect Unity to ROS 2 via TCP connector"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Sensor Simulation"}),": Implement camera and LiDAR sensors"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Synthetic Data"}),": Generate labeled datasets with domain randomization"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Best Practices"}),": Performance optimization and sim-to-real transfer"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"Unity complements Gazebo by providing photorealistic rendering for perception training. Many teams use Gazebo for control development and Unity for synthetic data generation."}),"\n",(0,s.jsxs)(e.p,{children:["Next, learn about ",(0,s.jsx)(e.a,{href:"/docs/module-2/digital-twin-workflows",children:"Digital Twin Workflows"})," to combine these tools into production systems."]}),"\n",(0,s.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://github.com/Unity-Technologies/Unity-Robotics-Hub",children:"Unity Robotics Hub"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://github.com/Unity-Technologies/com.unity.perception",children:"Unity Perception Package"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://github.com/Unity-Technologies/ROS-TCP-Connector",children:"ROS TCP Connector Documentation"})}),"\n",(0,s.jsx)(e.li,{children:(0,s.jsx)(e.a,{href:"https://docs.unity3d.com/Manual/class-ArticulationBody.html",children:"Unity Manual - ArticulationBody"})}),"\n"]})]})}function h(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>a});var t=i(6540);const s={},r=t.createContext(s);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);