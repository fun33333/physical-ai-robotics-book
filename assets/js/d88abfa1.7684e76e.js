"use strict";(globalThis.webpackChunkbook_website=globalThis.webpackChunkbook_website||[]).push([[4932],{2478:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"module-3/isaac-ros","title":"Isaac ROS","description":"GPU-accelerated perception with Isaac ROS: optimized packages for detection, segmentation, and SLAM.","source":"@site/docs/module-3/isaac-ros.md","sourceDirName":"module-3","slug":"/module-3/isaac-ros","permalink":"/physical-ai-robotics-book/docs/module-3/isaac-ros","draft":false,"unlisted":false,"editUrl":"https://github.com/fun33333/physical-ai-robotics-book/tree/main/book-website/docs/module-3/isaac-ros.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"title":"Isaac ROS","sidebar_position":4,"description":"GPU-accelerated perception with Isaac ROS: optimized packages for detection, segmentation, and SLAM."},"sidebar":"tutorialSidebar","previous":{"title":"Isaac Sim","permalink":"/physical-ai-robotics-book/docs/module-3/isaac-sim"},"next":{"title":"Isaac Lab (Reinforcement Learning)","permalink":"/physical-ai-robotics-book/docs/module-3/isaac-lab"}}');var t=i(4848),r=i(8453);const a={title:"Isaac ROS",sidebar_position:4,description:"GPU-accelerated perception with Isaac ROS: optimized packages for detection, segmentation, and SLAM."},c="Isaac ROS",o={},l=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Isaac ROS Architecture",id:"isaac-ros-architecture",level:2},{value:"Package Structure",id:"package-structure",level:3},{value:"Key Packages",id:"key-packages",level:3},{value:"Setup",id:"setup",level:2},{value:"Docker-Based Development",id:"docker-based-development",level:3},{value:"Native Installation (Advanced)",id:"native-installation-advanced",level:3},{value:"Object Detection",id:"object-detection",level:2},{value:"Using DetectNet",id:"using-detectnet",level:3},{value:"Custom Detection Model",id:"custom-detection-model",level:3},{value:"Visual SLAM",id:"visual-slam",level:2},{value:"cuVSLAM Setup",id:"cuvslam-setup",level:3},{value:"cuVSLAM Configuration",id:"cuvslam-configuration",level:3},{value:"SLAM Output Topics",id:"slam-output-topics",level:3},{value:"Semantic Segmentation",id:"semantic-segmentation",level:2},{value:"Using SegFormer",id:"using-segformer",level:3},{value:"Segmentation Classes",id:"segmentation-classes",level:3},{value:"Multi-Camera Pipeline",id:"multi-camera-pipeline",level:2},{value:"Pipeline Architecture",id:"pipeline-architecture",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"TensorRT Engine Generation",id:"tensorrt-engine-generation",level:3},{value:"NITROS Optimization",id:"nitros-optimization",level:3},{value:"Benchmark Results",id:"benchmark-results",level:3},{value:"Exercise 1: Object Detection Pipeline",id:"exercise-1-object-detection-pipeline",level:2},{value:"Exercise 2: Visual SLAM Integration",id:"exercise-2-visual-slam-integration",level:2},{value:"Exercise 3: Custom Model Deployment",id:"exercise-3-custom-model-deployment",level:2},{value:"Summary",id:"summary",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"isaac-ros",children:"Isaac ROS"})}),"\n",(0,t.jsx)(n.p,{children:"Isaac ROS provides GPU-accelerated implementations of common robotics perception algorithms, offering significant speedups over CPU-only alternatives. This chapter shows you how to deploy Isaac ROS packages in your perception pipeline for real-time performance on NVIDIA hardware."}),"\n",(0,t.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(n.p,{children:"In this section, you will:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Set up Isaac ROS development environment"}),"\n",(0,t.jsx)(n.li,{children:"Deploy pre-trained detection and segmentation models"}),"\n",(0,t.jsx)(n.li,{children:"Implement visual SLAM with cuVSLAM"}),"\n",(0,t.jsx)(n.li,{children:"Build multi-camera perception pipelines"}),"\n",(0,t.jsx)(n.li,{children:"Optimize inference with TensorRT"}),"\n",(0,t.jsx)(n.li,{children:"Integrate with existing ROS 2 systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ubuntu 22.04 with ROS 2 Humble"}),"\n",(0,t.jsx)(n.li,{children:"NVIDIA GPU (RTX series or Jetson)"}),"\n",(0,t.jsx)(n.li,{children:"Docker with NVIDIA Container Toolkit"}),"\n",(0,t.jsx)(n.li,{children:"NGC account with API key"}),"\n",(0,t.jsxs)(n.li,{children:["Completed ",(0,t.jsx)(n.a,{href:"/docs/module-3/isaac-platform-overview",children:"Isaac Platform Overview"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"isaac-ros-architecture",children:"Isaac ROS Architecture"}),"\n",(0,t.jsx)(n.h3,{id:"package-structure",children:"Package Structure"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Isaac ROS Package Hierarchy                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   Application Layer                      \u2502   \u2502\n\u2502   \u2502  isaac_ros_examples \u2022 Your Custom Nodes                  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                  Perception Packages                     \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502   \u2502\n\u2502   \u2502  \u2502 Detection   \u2502 \u2502 Segmentation \u2502 \u2502    SLAM         \u2502  \u2502   \u2502\n\u2502   \u2502  \u2502             \u2502 \u2502              \u2502 \u2502                 \u2502  \u2502   \u2502\n\u2502   \u2502  \u2502 detectnet   \u2502 \u2502 segformer    \u2502 \u2502 visual_slam     \u2502  \u2502   \u2502\n\u2502   \u2502  \u2502 yolov8      \u2502 \u2502 unet        \u2502 \u2502 nvblox          \u2502  \u2502   \u2502\n\u2502   \u2502  \u2502 rtdetr      \u2502 \u2502 bi3d         \u2502 \u2502                 \u2502  \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                   Core Infrastructure                    \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502   \u2502\n\u2502   \u2502  \u2502 dnn_inference \u2502 \u2502image_pipeline\u2502 \u2502 depth_image_proc\u2502 \u2502   \u2502\n\u2502   \u2502  \u2502 (TensorRT)    \u2502 \u2502(GPU resize) \u2502 \u2502  (CUDA accel)   \u2502 \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                        NITROS                            \u2502   \u2502\n\u2502   \u2502           Zero-copy GPU memory transfer                  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,t.jsx)(n.h3,{id:"key-packages",children:"Key Packages"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Package"}),(0,t.jsx)(n.th,{children:"Function"}),(0,t.jsx)(n.th,{children:"Performance"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_dnn_inference"})}),(0,t.jsx)(n.td,{children:"TensorRT inference"}),(0,t.jsx)(n.td,{children:"Up to 50x vs CPU"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_visual_slam"})}),(0,t.jsx)(n.td,{children:"cuVSLAM"}),(0,t.jsx)(n.td,{children:"Real-time 60 FPS"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_apriltag"})}),(0,t.jsx)(n.td,{children:"Fiducial detection"}),(0,t.jsx)(n.td,{children:"10x vs CPU"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_image_pipeline"})}),(0,t.jsx)(n.td,{children:"Image processing"}),(0,t.jsx)(n.td,{children:"GPU-accelerated"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_depth_image_proc"})}),(0,t.jsx)(n.td,{children:"Depth processing"}),(0,t.jsx)(n.td,{children:"CUDA kernels"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_detectnet"})}),(0,t.jsx)(n.td,{children:"Object detection"}),(0,t.jsx)(n.td,{children:"30+ FPS on RTX"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"isaac_ros_segformer"})}),(0,t.jsx)(n.td,{children:"Semantic segmentation"}),(0,t.jsx)(n.td,{children:"Real-time"})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,t.jsx)(n.h3,{id:"docker-based-development",children:"Docker-Based Development"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Isaac ROS Docker setup"',children:"# 1. Clone Isaac ROS common\nmkdir -p ~/workspaces/isaac_ros-dev/src\ncd ~/workspaces/isaac_ros-dev/src\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\n\n# 2. Clone desired packages\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_visual_slam.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_object_detection.git\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_dnn_inference.git\n\n# 3. Launch development container\ncd ~/workspaces/isaac_ros-dev/src/isaac_ros_common\n./scripts/run_dev.sh\n\n# Inside container:\n# 4. Build packages\ncd /workspaces/isaac_ros-dev\ncolcon build --symlink-install\n\n# 5. Source workspace\nsource install/setup.bash\n"})}),"\n",(0,t.jsx)(n.h3,{id:"native-installation-advanced",children:"Native Installation (Advanced)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Native Isaac ROS installation"',children:"# Install dependencies\nsudo apt install -y \\\n  ros-humble-vision-msgs \\\n  ros-humble-cv-bridge \\\n  ros-humble-image-transport\n\n# Install Isaac ROS apt packages\nsudo apt-key adv --fetch-keys https://isaac.download.nvidia.com/isaac-ros/repos.key\necho 'deb https://isaac.download.nvidia.com/isaac-ros/release-3 jammy main' | \\\n  sudo tee /etc/apt/sources.list.d/isaac-ros.list\n\nsudo apt update\nsudo apt install -y \\\n  ros-humble-isaac-ros-visual-slam \\\n  ros-humble-isaac-ros-apriltag \\\n  ros-humble-isaac-ros-dnn-inference\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"object-detection",children:"Object Detection"}),"\n",(0,t.jsx)(n.h3,{id:"using-detectnet",children:"Using DetectNet"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Launch DetectNet"',children:"# Download model (inside Docker)\nmkdir -p /tmp/models\ncd /tmp/models\nwget https://api.ngc.nvidia.com/v2/models/nvidia/tao/peoplenet/versions/pruned_quantized_decrypted_v2.3.3/files/resnet34_peoplenet_int8.etlt\n\n# Launch detection\nros2 launch isaac_ros_detectnet isaac_ros_detectnet.launch.py \\\n  model_file_path:=/tmp/models/resnet34_peoplenet_int8.etlt \\\n  engine_file_path:=/tmp/models/resnet34_peoplenet_int8.plan \\\n  input_binding_names:=['input_1'] \\\n  output_binding_names:=['output_cov/Sigmoid', 'output_bbox/BiasAdd'] \\\n  network_image_width:=960 \\\n  network_image_height:=544 \\\n  input_image_topic:=/camera/image_raw\n"})}),"\n",(0,t.jsx)(n.h3,{id:"custom-detection-model",children:"Custom Detection Model"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="custom_detection_node.py"',children:'"""Custom detection using Isaac ROS DNN inference."""\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nfrom isaac_ros_tensor_list_interfaces.msg import TensorList\n\nclass DetectionNode(Node):\n    def __init__(self):\n        super().__init__(\'custom_detection\')\n\n        # Subscribe to inference output\n        self.tensor_sub = self.create_subscription(\n            TensorList,\n            \'/tensor_pub\',\n            self.tensor_callback,\n            10\n        )\n\n        # Publish detections\n        self.detection_pub = self.create_publisher(\n            Detection2DArray,\n            \'/detections\',\n            10\n        )\n\n        self.get_logger().info(\'Detection node ready\')\n\n    def tensor_callback(self, msg: TensorList):\n        """Process inference output tensors."""\n        detections = Detection2DArray()\n        detections.header = msg.header\n\n        # Parse model-specific output format\n        # (Depends on your model architecture)\n        for tensor in msg.tensors:\n            # Process tensor.data based on model\n            pass\n\n        self.detection_pub.publish(detections)\n\n\ndef main():\n    rclpy.init()\n    node = DetectionNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"visual-slam",children:"Visual SLAM"}),"\n",(0,t.jsx)(n.h3,{id:"cuvslam-setup",children:"cuVSLAM Setup"}),"\n",(0,t.jsx)(n.p,{children:"cuVSLAM is NVIDIA's GPU-accelerated visual SLAM implementation:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Launch cuVSLAM"',children:"# For stereo camera\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py \\\n  enable_rectified_pose:=True \\\n  enable_imu:=True \\\n  enable_slam_visualization:=True \\\n  camera_info_topic:=/camera/left/camera_info \\\n  image_topic:=/camera/left/image_raw \\\n  right_camera_info_topic:=/camera/right/camera_info \\\n  right_image_topic:=/camera/right/image_raw \\\n  imu_topic:=/imu\n\n# For RealSense camera\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam_realsense.launch.py\n"})}),"\n",(0,t.jsx)(n.h3,{id:"cuvslam-configuration",children:"cuVSLAM Configuration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-yaml",metastring:'title="vslam_config.yaml"',children:'/**:\n  ros__parameters:\n    # Camera configuration\n    base_frame: "base_link"\n    map_frame: "map"\n    odom_frame: "odom"\n\n    # Feature tracking\n    num_cameras: 2\n    enable_observations_view: true\n    enable_landmarks_view: true\n\n    # IMU integration\n    enable_imu_fusion: true\n    gyro_noise_density: 0.00016\n    gyro_random_walk: 0.000002\n    accel_noise_density: 0.0006\n    accel_random_walk: 0.0003\n\n    # Performance tuning\n    image_jitter_threshold_ms: 35.0\n    enable_debug_mode: false\n    enable_localization_n_mapping: true\n'})}),"\n",(0,t.jsx)(n.h3,{id:"slam-output-topics",children:"SLAM Output Topics"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Topic"}),(0,t.jsx)(n.th,{children:"Type"}),(0,t.jsx)(n.th,{children:"Description"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/visual_slam/tracking/odometry"})}),(0,t.jsx)(n.td,{children:"Odometry"}),(0,t.jsx)(n.td,{children:"6DOF pose at 60+ Hz"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/visual_slam/tracking/slam_path"})}),(0,t.jsx)(n.td,{children:"Path"}),(0,t.jsx)(n.td,{children:"Trajectory history"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/visual_slam/vis/landmarks_cloud"})}),(0,t.jsx)(n.td,{children:"PointCloud2"}),(0,t.jsx)(n.td,{children:"3D feature map"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"/visual_slam/status"})}),(0,t.jsx)(n.td,{children:"DiagnosticArray"}),(0,t.jsx)(n.td,{children:"Tracking status"})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"semantic-segmentation",children:"Semantic Segmentation"}),"\n",(0,t.jsx)(n.h3,{id:"using-segformer",children:"Using SegFormer"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Launch SegFormer"',children:"# Download model\nmkdir -p /tmp/models\n# Get model from NGC catalog\n\n# Launch segmentation\nros2 launch isaac_ros_segformer isaac_ros_segformer.launch.py \\\n  model_file_path:=/tmp/models/segformer.onnx \\\n  engine_file_path:=/tmp/models/segformer.plan \\\n  input_image_topic:=/camera/image_raw \\\n  network_image_width:=1024 \\\n  network_image_height:=1024\n"})}),"\n",(0,t.jsx)(n.h3,{id:"segmentation-classes",children:"Segmentation Classes"}),"\n",(0,t.jsx)(n.p,{children:"Default SegFormer outputs include:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Class ID"}),(0,t.jsx)(n.th,{children:"Label"}),(0,t.jsx)(n.th,{children:"Color (RGB)"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"0"}),(0,t.jsx)(n.td,{children:"Background"}),(0,t.jsx)(n.td,{children:"(0, 0, 0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"1"}),(0,t.jsx)(n.td,{children:"Person"}),(0,t.jsx)(n.td,{children:"(255, 0, 0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"2"}),(0,t.jsx)(n.td,{children:"Vehicle"}),(0,t.jsx)(n.td,{children:"(0, 255, 0)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"3"}),(0,t.jsx)(n.td,{children:"Road"}),(0,t.jsx)(n.td,{children:"(128, 128, 128)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"..."}),(0,t.jsx)(n.td,{children:"..."}),(0,t.jsx)(n.td,{children:"..."})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"multi-camera-pipeline",children:"Multi-Camera Pipeline"}),"\n",(0,t.jsx)(n.h3,{id:"pipeline-architecture",children:"Pipeline Architecture"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="multi_camera_pipeline.launch.py"',children:"\"\"\"Multi-camera perception pipeline.\"\"\"\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node, ComposableNodeContainer\nfrom launch_ros.descriptions import ComposableNode\n\ndef generate_launch_description():\n    # Define cameras\n    cameras = ['front', 'left', 'right']\n\n    nodes = []\n\n    for camera in cameras:\n        # Image rectification\n        rectify_node = ComposableNode(\n            package='isaac_ros_image_pipeline',\n            plugin='nvidia::isaac_ros::image_pipeline::RectifyNode',\n            name=f'{camera}_rectify',\n            parameters=[{\n                'output_width': 640,\n                'output_height': 480,\n            }],\n            remappings=[\n                ('image_raw', f'/{camera}/image_raw'),\n                ('camera_info', f'/{camera}/camera_info'),\n                ('image_rect', f'/{camera}/image_rect'),\n            ]\n        )\n        nodes.append(rectify_node)\n\n    # Detection (shared across cameras)\n    detection_node = ComposableNode(\n        package='isaac_ros_detectnet',\n        plugin='nvidia::isaac_ros::detectnet::DetectNetDecoderNode',\n        name='detectnet',\n        parameters=[{\n            'model_file_path': '/tmp/models/peoplenet.plan',\n        }]\n    )\n    nodes.append(detection_node)\n\n    # Container for zero-copy communication\n    container = ComposableNodeContainer(\n        name='perception_container',\n        namespace='',\n        package='rclcpp_components',\n        executable='component_container_mt',\n        composable_node_descriptions=nodes,\n        output='screen'\n    )\n\n    return LaunchDescription([container])\n"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,t.jsx)(n.h3,{id:"tensorrt-engine-generation",children:"TensorRT Engine Generation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",metastring:'title="Generate TensorRT engine"',children:"# Convert ONNX to TensorRT\n/usr/src/tensorrt/bin/trtexec \\\n  --onnx=/tmp/models/model.onnx \\\n  --saveEngine=/tmp/models/model.plan \\\n  --fp16 \\\n  --workspace=4096 \\\n  --verbose\n\n# For INT8 quantization (requires calibration data)\n/usr/src/tensorrt/bin/trtexec \\\n  --onnx=/tmp/models/model.onnx \\\n  --saveEngine=/tmp/models/model_int8.plan \\\n  --int8 \\\n  --calib=/tmp/calibration_cache.bin\n"})}),"\n",(0,t.jsx)(n.h3,{id:"nitros-optimization",children:"NITROS Optimization"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",metastring:'title="Enable NITROS"',children:"\"\"\"Enable NITROS for zero-copy GPU transfer.\"\"\"\nfrom launch_ros.descriptions import ComposableNode\n\n# NITROS-enabled node configuration\nnode = ComposableNode(\n    package='isaac_ros_dnn_inference',\n    plugin='nvidia::isaac_ros::dnn_inference::TensorRTNode',\n    name='tensorrt_node',\n    parameters=[{\n        # NITROS is enabled by default in composable nodes\n        'enable_nitros': True,\n        'nitros_format': 'nitros_tensor_list_nchw_rgb_f32',\n    }]\n)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"benchmark-results",children:"Benchmark Results"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Task"}),(0,t.jsx)(n.th,{children:"CPU (Intel i7)"}),(0,t.jsx)(n.th,{children:"GPU (RTX 3060)"}),(0,t.jsx)(n.th,{children:"Speedup"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"YOLOv8 (640x640)"}),(0,t.jsx)(n.td,{children:"50ms"}),(0,t.jsx)(n.td,{children:"5ms"}),(0,t.jsx)(n.td,{children:"10x"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"SegFormer"}),(0,t.jsx)(n.td,{children:"200ms"}),(0,t.jsx)(n.td,{children:"15ms"}),(0,t.jsx)(n.td,{children:"13x"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Visual SLAM"}),(0,t.jsx)(n.td,{children:"100ms"}),(0,t.jsx)(n.td,{children:"8ms"}),(0,t.jsx)(n.td,{children:"12x"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Depth estimation"}),(0,t.jsx)(n.td,{children:"80ms"}),(0,t.jsx)(n.td,{children:"6ms"}),(0,t.jsx)(n.td,{children:"13x"})]})]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"exercise-1-object-detection-pipeline",children:"Exercise 1: Object Detection Pipeline"}),"\n",(0,t.jsxs)(n.admonition,{title:"Exercise 1: Deploy PeopleNet",type:"tip",children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective"}),": Set up real-time people detection."]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Steps"}),":"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Launch Isaac ROS container"}),"\n",(0,t.jsx)(n.li,{children:"Download PeopleNet model from NGC"}),"\n",(0,t.jsx)(n.li,{children:"Generate TensorRT engine"}),"\n",(0,t.jsx)(n.li,{children:"Launch DetectNet node"}),"\n",(0,t.jsx)(n.li,{children:"Visualize detections in RViz2"}),"\n"]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Verification"}),":"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Check detection rate\nros2 topic hz /detectnet/detections\n# Should be 20+ Hz\n\n# View detections\nros2 topic echo /detectnet/detections\n"})}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Time Estimate"}),": 30 minutes"]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"exercise-2-visual-slam-integration",children:"Exercise 2: Visual SLAM Integration"}),"\n",(0,t.jsxs)(n.admonition,{title:"Exercise 2: cuVSLAM with RealSense",type:"tip",children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective"}),": Run visual SLAM with Intel RealSense camera."]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Steps"}),":"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Connect RealSense D435i camera"}),"\n",(0,t.jsx)(n.li,{children:"Launch RealSense ROS 2 driver"}),"\n",(0,t.jsx)(n.li,{children:"Configure cuVSLAM for RealSense"}),"\n",(0,t.jsx)(n.li,{children:"Run SLAM and build map"}),"\n",(0,t.jsx)(n.li,{children:"Save map for localization"}),"\n"]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Expected Output"}),":"]}),(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Odometry at 60 Hz"}),"\n",(0,t.jsx)(n.li,{children:"3D landmark map"}),"\n",(0,t.jsx)(n.li,{children:"Trajectory visualization"}),"\n"]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Time Estimate"}),": 45 minutes"]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"exercise-3-custom-model-deployment",children:"Exercise 3: Custom Model Deployment"}),"\n",(0,t.jsxs)(n.admonition,{title:"Exercise 3: Deploy Your Own Model",type:"tip",children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Objective"}),": Convert and deploy a custom detection model."]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Steps"}),":"]}),(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Export PyTorch model to ONNX"}),"\n",(0,t.jsxs)(n.li,{children:["Generate TensorRT engine with ",(0,t.jsx)(n.code,{children:"trtexec"})]}),"\n",(0,t.jsx)(n.li,{children:"Create Isaac ROS launch file"}),"\n",(0,t.jsx)(n.li,{children:"Write decoder node for your model output"}),"\n",(0,t.jsx)(n.li,{children:"Test with camera input"}),"\n"]}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Model Export"}),":"]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import torch\nmodel = YourModel()\nmodel.load_state_dict(torch.load('weights.pth'))\nmodel.eval()\n\ndummy_input = torch.randn(1, 3, 640, 640)\ntorch.onnx.export(model, dummy_input, 'model.onnx',\n                  opset_version=13,\n                  input_names=['input'],\n                  output_names=['output'])\n"})}),(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Time Estimate"}),": 90 minutes"]})]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"In this chapter, you learned:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Setup"}),": Deploy Isaac ROS via Docker or native installation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Detection"}),": Run real-time object detection with DetectNet"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"SLAM"}),": Implement visual SLAM with cuVSLAM"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Segmentation"}),": Deploy semantic segmentation models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Optimization"}),": Use TensorRT and NITROS for maximum performance"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Isaac ROS enables perception capabilities that would be impossible with CPU-only approaches, making real-time robotics applications practical on embedded and desktop hardware."}),"\n",(0,t.jsxs)(n.p,{children:["Next, explore ",(0,t.jsx)(n.a,{href:"/docs/module-3/isaac-lab",children:"Isaac Lab"})," to learn reinforcement learning for robot control."]}),"\n",(0,t.jsx)(n.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://nvidia-isaac-ros.github.io/",children:"Isaac ROS Documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS",children:"Isaac ROS GitHub"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://developer.nvidia.com/tensorrt",children:"TensorRT Documentation"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://developer.nvidia.com/isaac-ros-visual-slam",children:"cuVSLAM Paper"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>c});var s=i(6540);const t={},r=s.createContext(t);function a(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);