"use strict";(globalThis.webpackChunkbook_website=globalThis.webpackChunkbook_website||[]).push([[2163],{5169:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"assessments/projects","title":"Hands-on Projects","description":"Detailed descriptions of hands-on projects that demonstrate practical Physical AI skills.","source":"@site/docs/assessments/projects.md","sourceDirName":"assessments","slug":"/assessments/projects","permalink":"/physical-ai-robotics-book/docs/assessments/projects","draft":false,"unlisted":false,"editUrl":"https://github.com/fun33333/physical-ai-robotics-book/tree/main/book-website/docs/assessments/projects.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"title":"Hands-on Projects","sidebar_position":2,"description":"Detailed descriptions of hands-on projects that demonstrate practical Physical AI skills."},"sidebar":"tutorialSidebar","previous":{"title":"Assessments","permalink":"/physical-ai-robotics-book/docs/assessments/"},"next":{"title":"Knowledge Checks","permalink":"/physical-ai-robotics-book/docs/assessments/quizzes"}}');var r=i(4848),t=i(8453);const l={title:"Hands-on Projects",sidebar_position:2,description:"Detailed descriptions of hands-on projects that demonstrate practical Physical AI skills."},c="Hands-on Projects",o={},d=[{value:"Project Overview",id:"project-overview",level:2},{value:"Project 1: ROS 2 Robot Controller",id:"project-1-ros-2-robot-controller",level:2},{value:"Overview",id:"overview",level:3},{value:"Learning Objectives",id:"learning-objectives",level:3},{value:"System Architecture",id:"system-architecture",level:3},{value:"Requirements",id:"requirements",level:3},{value:"Functional Requirements",id:"functional-requirements",level:4},{value:"Technical Requirements",id:"technical-requirements",level:4},{value:"Deliverables",id:"deliverables",level:3},{value:"Rubric",id:"rubric",level:3},{value:"Suggested Approach",id:"suggested-approach",level:3},{value:"Extension Challenges",id:"extension-challenges",level:3},{value:"Starter Code",id:"starter-code",level:3},{value:"Project 2: Simulation Environment",id:"project-2-simulation-environment",level:2},{value:"Overview",id:"overview-1",level:3},{value:"Learning Objectives",id:"learning-objectives-1",level:3},{value:"System Architecture",id:"system-architecture-1",level:3},{value:"Requirements",id:"requirements-1",level:3},{value:"Robot Model Requirements",id:"robot-model-requirements",level:4},{value:"World Requirements",id:"world-requirements",level:4},{value:"Integration Requirements",id:"integration-requirements",level:4},{value:"Deliverables",id:"deliverables-1",level:3},{value:"Rubric",id:"rubric-1",level:3},{value:"Suggested Approach",id:"suggested-approach-1",level:3},{value:"Extension Challenges",id:"extension-challenges-1",level:3},{value:"Starter Code",id:"starter-code-1",level:3},{value:"Project 3: Isaac Perception Pipeline",id:"project-3-isaac-perception-pipeline",level:2},{value:"Overview",id:"overview-2",level:3},{value:"Learning Objectives",id:"learning-objectives-2",level:3},{value:"System Architecture",id:"system-architecture-2",level:3},{value:"Requirements",id:"requirements-2",level:3},{value:"Core Pipeline Requirements",id:"core-pipeline-requirements",level:4},{value:"Performance Requirements",id:"performance-requirements",level:4},{value:"Integration Requirements",id:"integration-requirements-1",level:4},{value:"Deliverables",id:"deliverables-2",level:3},{value:"Rubric",id:"rubric-2",level:3},{value:"Suggested Approach",id:"suggested-approach-2",level:3},{value:"Extension Challenges",id:"extension-challenges-2",level:3},{value:"Starter Code",id:"starter-code-2",level:3},{value:"Project 4: VLA Demo System",id:"project-4-vla-demo-system",level:2},{value:"Overview",id:"overview-3",level:3},{value:"Learning Objectives",id:"learning-objectives-3",level:3},{value:"System Architecture",id:"system-architecture-3",level:3},{value:"Requirements",id:"requirements-3",level:3},{value:"Core Pipeline Requirements",id:"core-pipeline-requirements-1",level:4},{value:"Integration Requirements",id:"integration-requirements-2",level:4},{value:"Deliverables",id:"deliverables-3",level:3},{value:"Rubric",id:"rubric-3",level:3},{value:"Suggested Approach",id:"suggested-approach-3",level:3},{value:"Extension Challenges",id:"extension-challenges-3",level:3},{value:"Starter Code Structure",id:"starter-code-structure",level:3},{value:"Resources",id:"resources",level:3},{value:"Capstone Project",id:"capstone-project",level:2},{value:"Overview",id:"overview-4",level:3},{value:"Learning Objectives",id:"learning-objectives-4",level:3},{value:"System Architecture",id:"system-architecture-4",level:3},{value:"Requirements",id:"requirements-4",level:3},{value:"Core System Requirements",id:"core-system-requirements",level:4},{value:"Integration Requirements",id:"integration-requirements-3",level:4},{value:"Deliverables",id:"deliverables-4",level:3},{value:"Rubric",id:"rubric-4",level:3},{value:"Suggested Approach",id:"suggested-approach-4",level:3},{value:"Extension Challenges",id:"extension-challenges-4",level:3},{value:"Architecture Considerations",id:"architecture-considerations",level:3},{value:"Resources",id:"resources-1",level:3},{value:"Submission Guidelines",id:"submission-guidelines",level:2},{value:"Format",id:"format",level:3},{value:"Grading Timeline",id:"grading-timeline",level:3},{value:"Academic Integrity",id:"academic-integrity",level:3}];function a(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"hands-on-projects",children:"Hands-on Projects"})}),"\n",(0,r.jsx)(n.p,{children:"Projects are the heart of assessment in this curriculum. Each module culminates in a practical project that demonstrates mastery of the covered material and produces artifacts you can include in your portfolio."}),"\n",(0,r.jsx)(n.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Project"}),(0,r.jsx)(n.th,{children:"Module"}),(0,r.jsx)(n.th,{children:"Focus"}),(0,r.jsx)(n.th,{children:"Difficulty"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#project-1-ros-2-robot-controller",children:"ROS 2 Robot Controller"})}),(0,r.jsx)(n.td,{children:"Module 1"}),(0,r.jsx)(n.td,{children:"Communication patterns, system integration"}),(0,r.jsx)(n.td,{children:"Intermediate"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#project-2-simulation-environment",children:"Simulation Environment"})}),(0,r.jsx)(n.td,{children:"Module 2"}),(0,r.jsx)(n.td,{children:"Gazebo, URDF, sensor simulation"}),(0,r.jsx)(n.td,{children:"Intermediate"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#project-3-isaac-perception-pipeline",children:"Isaac Perception Pipeline"})}),(0,r.jsx)(n.td,{children:"Module 3"}),(0,r.jsx)(n.td,{children:"GPU-accelerated perception"}),(0,r.jsx)(n.td,{children:"Advanced"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#project-4-vla-demo-system",children:"VLA Demo System"})}),(0,r.jsx)(n.td,{children:"Module 4"}),(0,r.jsx)(n.td,{children:"Vision-language-action integration"}),(0,r.jsx)(n.td,{children:"Advanced"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.a,{href:"#capstone-project",children:"Capstone: Autonomous Assistant"})}),(0,r.jsx)(n.td,{children:"All"}),(0,r.jsx)(n.td,{children:"Full integration"}),(0,r.jsx)(n.td,{children:"Expert"})]})]})]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"project-1-ros-2-robot-controller",children:"Project 1: ROS 2 Robot Controller"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Module"}),": 1 - The Robotic Nervous System (ROS 2)"]}),"\n",(0,r.jsx)(n.h3,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Build a complete ROS 2 application that demonstrates mastery of core communication patterns. You will create a multi-node system that simulates a robot with sensors, a controller, and a mission system that coordinates autonomous behavior."}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this project, you will demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Proper ROS 2 package structure and build configuration"}),"\n",(0,r.jsx)(n.li,{children:"Implementation of all three communication patterns (topics, services, actions)"}),"\n",(0,r.jsx)(n.li,{children:"Lifecycle node management for controlled startup/shutdown"}),"\n",(0,r.jsx)(n.li,{children:"System integration across multiple communicating nodes"}),"\n",(0,r.jsx)(n.li,{children:"Use of ROS 2 tools for debugging and introspection"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"system-architecture",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     Robot Controller System                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        Topics         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502   \u2502   Sensor     \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6  \u2502  Controller  \u2502       \u2502\n\u2502   \u2502   Nodes      \u2502  /sensors/battery     \u2502     Node     \u2502       \u2502\n\u2502   \u2502              \u2502  /sensors/position    \u2502              \u2502       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                 \u2502               \u2502\n\u2502                                          Services/Actions       \u2502\n\u2502                                                 \u2502               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510        Actions        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502   \u2502   Mission    \u2502 \u25c0\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502    Robot     \u2502       \u2502\n\u2502   \u2502   Planner    \u2502  /navigate_to_goal   \u2502   State      \u2502       \u2502\n\u2502   \u2502              \u2502  (feedback/result)    \u2502   Server     \u2502       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requirements",children:"Requirements"}),"\n",(0,r.jsx)(n.h4,{id:"functional-requirements",children:"Functional Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sensor Simulation Node"})," (Lifecycle Node)"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Publish simulated battery level (0-100%) on ",(0,r.jsx)(n.code,{children:"/sensors/battery"})]}),"\n",(0,r.jsxs)(n.li,{children:["Publish simulated position (x, y, theta) on ",(0,r.jsx)(n.code,{children:"/sensors/position"})]}),"\n",(0,r.jsx)(n.li,{children:"Support lifecycle transitions (configure, activate, deactivate)"}),"\n",(0,r.jsx)(n.li,{children:"Battery should decrease over time when active"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Robot State Server Node"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Provide ",(0,r.jsx)(n.code,{children:"/robot/get_state"})," service returning current robot state"]}),"\n",(0,r.jsxs)(n.li,{children:["Provide ",(0,r.jsx)(n.code,{children:"/robot/set_mode"})," service to change operating mode (idle, patrol, charge)"]}),"\n",(0,r.jsx)(n.li,{children:"Maintain internal state machine for mode transitions"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Navigation Action Server"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Accept ",(0,r.jsx)(n.code,{children:"/navigate_to_goal"})," action with target position"]}),"\n",(0,r.jsx)(n.li,{children:"Publish feedback with current position and distance remaining"}),"\n",(0,r.jsx)(n.li,{children:"Support goal cancellation"}),"\n",(0,r.jsx)(n.li,{children:"Simulate movement at configurable speed"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Mission Controller Node"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Subscribe to sensor topics"}),"\n",(0,r.jsx)(n.li,{children:"Monitor battery and trigger charging mode when low (< 20%)"}),"\n",(0,r.jsx)(n.li,{children:"Execute patrol mission: visit 3 waypoints in sequence"}),"\n",(0,r.jsx)(n.li,{children:"Use action client to send navigation goals"}),"\n",(0,r.jsx)(n.li,{children:"Log mission progress"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"technical-requirements",children:"Technical Requirements"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["All nodes in a single package named ",(0,r.jsx)(n.code,{children:"robot_controller"})]}),"\n",(0,r.jsx)(n.li,{children:"Use Python (rclpy) for implementation"}),"\n",(0,r.jsx)(n.li,{children:"Include launch file that starts all nodes"}),"\n",(0,r.jsx)(n.li,{children:"Include parameter file for configurable values"}),"\n",(0,r.jsxs)(n.li,{children:["Pass ",(0,r.jsx)(n.code,{children:"colcon build"})," and ",(0,r.jsx)(n.code,{children:"colcon test"})," without errors"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deliverables",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","ROS 2 package ",(0,r.jsx)(n.code,{children:"robot_controller"})," with proper structure"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Sensor simulation node with lifecycle support"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Robot state server with services"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Navigation action server"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Mission controller node"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Launch file (",(0,r.jsx)(n.code,{children:"robot_system.launch.py"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Parameter file (",(0,r.jsx)(n.code,{children:"robot_params.yaml"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","README with architecture diagram and usage instructions"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rubric",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Sensor Node"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Lifecycle-managed, publishes battery and position"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"State Server"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Services work correctly, state machine logic"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Action Server"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Navigation with feedback, cancellation support"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Mission Controller"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Coordinates system, handles battery warnings"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Code Quality"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Clean code, comments, follows ROS 2 conventions"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Documentation"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"README, architecture diagram, usage examples"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Bonus Features"})}),(0,r.jsx)(n.td,{children:"+10"}),(0,r.jsx)(n.td,{children:"Additional features beyond requirements"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Total"}),": 100 points (110 with bonus)\n",(0,r.jsx)(n.strong,{children:"Passing"}),": 70 points"]}),"\n",(0,r.jsx)(n.h3,{id:"suggested-approach",children:"Suggested Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 1"}),": Create package structure, implement sensor node"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 1"}),": Add state server with services"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 2"}),": Implement action server"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 2"}),": Build mission controller, integrate system"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"extension-challenges",children:"Extension Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add a second robot and implement multi-robot coordination"}),"\n",(0,r.jsx)(n.li,{children:"Implement obstacle detection that pauses navigation"}),"\n",(0,r.jsx)(n.li,{children:"Add RViz visualization markers for robot position"}),"\n",(0,r.jsx)(n.li,{children:"Create a GUI using rqt for mission control"}),"\n",(0,r.jsx)(n.li,{children:"Add unit tests for all nodes"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"starter-code",children:"Starter Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="robot_controller/sensor_node.py"',children:"import rclpy\nfrom rclpy.lifecycle import Node as LifecycleNode\nfrom rclpy.lifecycle import State, TransitionCallbackReturn\nfrom std_msgs.msg import Float32\nfrom geometry_msgs.msg import Pose2D\n\n\nclass SensorNode(LifecycleNode):\n    \"\"\"Simulated sensor node with lifecycle management.\"\"\"\n\n    def __init__(self):\n        super().__init__('sensor_node')\n        # TODO: Initialize publishers (but don't create until configure)\n        self.battery_pub = None\n        self.position_pub = None\n        self.timer = None\n\n    def on_configure(self, state: State) -> TransitionCallbackReturn:\n        # TODO: Create publishers, declare parameters\n        self.get_logger().info('Configuring...')\n        return TransitionCallbackReturn.SUCCESS\n\n    def on_activate(self, state: State) -> TransitionCallbackReturn:\n        # TODO: Create timer, start publishing\n        self.get_logger().info('Activating...')\n        return TransitionCallbackReturn.SUCCESS\n\n    def on_deactivate(self, state: State) -> TransitionCallbackReturn:\n        # TODO: Stop timer\n        self.get_logger().info('Deactivating...')\n        return TransitionCallbackReturn.SUCCESS\n\n    def publish_sensors(self):\n        # TODO: Publish battery and position\n        pass\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SensorNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"project-2-simulation-environment",children:"Project 2: Simulation Environment"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Module"}),": 2 - Digital Twins and Simulation"]}),"\n",(0,r.jsx)(n.h3,{id:"overview-1",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Create a complete simulation environment for a mobile robot in Gazebo, including URDF robot description, sensor simulation, and ROS 2 integration. The environment should enable testing of navigation and perception algorithms without physical hardware."}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives-1",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this project, you will demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Creating valid URDF robot descriptions with proper kinematics and dynamics"}),"\n",(0,r.jsx)(n.li,{children:"Configuring Gazebo sensors (camera, LiDAR, IMU) with realistic noise models"}),"\n",(0,r.jsx)(n.li,{children:"Setting up ROS 2-Gazebo bridges for sensor data and control"}),"\n",(0,r.jsx)(n.li,{children:"Building custom Gazebo worlds with static and dynamic obstacles"}),"\n",(0,r.jsx)(n.li,{children:"Implementing hardware abstraction for simulation/real portability"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"system-architecture-1",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Simulation Environment System                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502                    Gazebo Sim                         \u2502      \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502      \u2502\n\u2502   \u2502  \u2502   Robot     \u2502  \u2502   World     \u2502  \u2502   Physics   \u2502  \u2502      \u2502\n\u2502   \u2502  \u2502   Model     \u2502  \u2502   (SDF)     \u2502  \u2502   Engine    \u2502  \u2502      \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                              \u2502                                   \u2502\n\u2502                       ros_gz_bridge                              \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502                      ROS 2                            \u2502      \u2502\n\u2502   \u2502  /camera/image    /scan    /imu    /cmd_vel    /odom \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502   \u2502              Application Nodes                        \u2502      \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502      \u2502\n\u2502   \u2502  \u2502  Teleop     \u2502  \u2502  Obstacle   \u2502  \u2502   RViz2     \u2502  \u2502      \u2502\n\u2502   \u2502  \u2502  Control    \u2502  \u2502  Detector   \u2502  \u2502   Viz       \u2502  \u2502      \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requirements-1",children:"Requirements"}),"\n",(0,r.jsx)(n.h4,{id:"robot-model-requirements",children:"Robot Model Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"URDF Robot Description"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Differential drive base with two wheels and caster"}),"\n",(0,r.jsxs)(n.li,{children:["Proper ",(0,r.jsx)(n.code,{children:"<inertial>"})," properties on all links"]}),"\n",(0,r.jsxs)(n.li,{children:["Correct ",(0,r.jsx)(n.code,{children:"<collision>"})," geometry for physics"]}),"\n",(0,r.jsx)(n.li,{children:"Visually distinct materials/colors"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Sensor Configuration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"RGB camera: 640x480, 30Hz, mounted on front"}),"\n",(0,r.jsx)(n.li,{children:"2D LiDAR: 360\xb0 scan, 10Hz, mounted on top"}),"\n",(0,r.jsx)(n.li,{children:"IMU: 100Hz, attached to base_link"}),"\n",(0,r.jsx)(n.li,{children:"All sensors with appropriate noise models"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Control Interface"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Differential drive plugin accepting ",(0,r.jsx)(n.code,{children:"/cmd_vel"})]}),"\n",(0,r.jsxs)(n.li,{children:["Odometry output on ",(0,r.jsx)(n.code,{children:"/odom"})]}),"\n",(0,r.jsx)(n.li,{children:"Joint state publishing for wheel positions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"world-requirements",children:"World Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Environment Design"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Indoor warehouse-style environment (~20m x 20m)"}),"\n",(0,r.jsx)(n.li,{children:"At least 10 static obstacles (shelves, boxes, walls)"}),"\n",(0,r.jsx)(n.li,{children:"At least 2 different floor textures"}),"\n",(0,r.jsx)(n.li,{children:"Proper lighting with shadows"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Testing Scenarios"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Clear path corridor for basic navigation"}),"\n",(0,r.jsx)(n.li,{children:"Tight passage requiring precise control"}),"\n",(0,r.jsx)(n.li,{children:"Open area with scattered obstacles"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"integration-requirements",children:"Integration Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Bridge Configuration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"YAML configuration file for all topic bridges"}),"\n",(0,r.jsx)(n.li,{children:"Proper frame_id configuration for all sensors"}),"\n",(0,r.jsx)(n.li,{children:"Clock synchronization enabled"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Launch Files"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"simulation.launch.py"}),": Start Gazebo, spawn robot, launch bridges"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"visualization.launch.py"}),": RViz2 with pre-configured displays"]}),"\n",(0,r.jsxs)(n.li,{children:["Support for ",(0,r.jsx)(n.code,{children:"headless:=true"})," parameter"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deliverables-1",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","URDF file with complete robot description (",(0,r.jsx)(n.code,{children:"robot.urdf.xacro"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Gazebo-specific sensor/plugin configurations (",(0,r.jsx)(n.code,{children:"robot_gazebo.xacro"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","World file with warehouse environment (",(0,r.jsx)(n.code,{children:"warehouse.sdf"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Bridge configuration file (",(0,r.jsx)(n.code,{children:"bridge_config.yaml"}),")"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Launch files for simulation and visualization"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","RViz2 configuration file with all sensor displays"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","README with setup instructions and screenshots"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Short video (1-2 min) demonstrating the environment"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rubric-1",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"URDF Quality"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Valid URDF, proper inertials, collision geometry"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Sensor Config"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Camera, LiDAR, IMU working with noise models"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"World Design"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Realistic environment with varied obstacles"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"ROS 2 Integration"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Bridges work, topics publish correctly"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Launch Files"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Clean launch structure, configurable parameters"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Documentation"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Clear README, architecture diagram, screenshots"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Bonus Features"})}),(0,r.jsx)(n.td,{children:"+10"}),(0,r.jsx)(n.td,{children:"Dynamic obstacles, multiple robots, Unity version"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Total"}),": 100 points (110 with bonus)\n",(0,r.jsx)(n.strong,{children:"Passing"}),": 70 points"]}),"\n",(0,r.jsx)(n.h3,{id:"suggested-approach-1",children:"Suggested Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 1-2"}),": Create basic URDF with base and wheels"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 3-4"}),": Add sensors (camera, LiDAR, IMU)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 5-6"}),": Build warehouse world"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 7-8"}),": Configure bridges and launch files"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 9-10"}),": Polish, document, and test"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"extension-challenges-1",children:"Extension Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add a manipulator arm to the robot"}),"\n",(0,r.jsx)(n.li,{children:"Implement dynamic obstacles that move"}),"\n",(0,r.jsx)(n.li,{children:"Create a Unity version for perception training"}),"\n",(0,r.jsx)(n.li,{children:"Add multiple robots with different configurations"}),"\n",(0,r.jsx)(n.li,{children:"Implement simulation-to-real validation metrics"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"starter-code-1",children:"Starter Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",metastring:'title="robot.urdf.xacro"',children:'<?xml version="1.0"?>\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="sim_robot">\n  \x3c!-- Properties --\x3e\n  <xacro:property name="base_width" value="0.3"/>\n  <xacro:property name="base_length" value="0.5"/>\n  <xacro:property name="base_height" value="0.1"/>\n  <xacro:property name="wheel_radius" value="0.1"/>\n  <xacro:property name="wheel_width" value="0.05"/>\n\n  \x3c!-- Base Link --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n      <material name="blue">\n        <color rgba="0.0 0.0 0.8 1.0"/>\n      </material>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="${base_length} ${base_width} ${base_height}"/>\n      </geometry>\n    </collision>\n    <inertial>\n      \x3c!-- TODO: Add proper inertial properties --\x3e\n      <mass value="5.0"/>\n      <inertia ixx="0.1" ixy="0" ixz="0" iyy="0.1" iyz="0" izz="0.1"/>\n    </inertial>\n  </link>\n\n  \x3c!-- TODO: Add wheels with joints --\x3e\n  \x3c!-- TODO: Add caster wheel --\x3e\n  \x3c!-- TODO: Add sensor links (camera_link, lidar_link) --\x3e\n\n  \x3c!-- Include Gazebo-specific configurations --\x3e\n  <xacro:include filename="$(find my_robot)/urdf/robot_gazebo.xacro"/>\n</robot>\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",metastring:'title="bridge_config.yaml"',children:'# ROS 2-Gazebo Bridge Configuration\n# Direction: GZ_TO_ROS for sensors, ROS_TO_GZ for commands\n\n# Camera\n- ros_topic_name: "/camera/image_raw"\n  gz_topic_name: "/world/warehouse/model/sim_robot/link/camera_link/sensor/camera/image"\n  ros_type_name: "sensor_msgs/msg/Image"\n  gz_type_name: "gz.msgs.Image"\n  direction: GZ_TO_ROS\n\n# TODO: Add LiDAR bridge\n# TODO: Add IMU bridge\n# TODO: Add cmd_vel bridge (ROS_TO_GZ)\n# TODO: Add odometry bridge\n# TODO: Add clock bridge\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"project-3-isaac-perception-pipeline",children:"Project 3: Isaac Perception Pipeline"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Module"}),": 3 - The AI-Robot Brain (NVIDIA Isaac)"]}),"\n",(0,r.jsx)(n.h3,{id:"overview-2",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Build a GPU-accelerated perception pipeline using Isaac ROS that processes camera and depth data to detect and localize objects in real-time. The system should demonstrate the performance benefits of GPU acceleration while integrating with a standard ROS 2 navigation stack."}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives-2",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this project, you will demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Setting up Isaac ROS development environment with Docker"}),"\n",(0,r.jsx)(n.li,{children:"Deploying pre-trained detection models using TensorRT"}),"\n",(0,r.jsx)(n.li,{children:"Implementing multi-sensor fusion for 3D object localization"}),"\n",(0,r.jsx)(n.li,{children:"Building real-time object tracking across frames"}),"\n",(0,r.jsx)(n.li,{children:"Optimizing perception pipelines for production deployment"}),"\n",(0,r.jsx)(n.li,{children:"Integrating GPU-accelerated perception with ROS 2 systems"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"system-architecture-2",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Isaac Perception Pipeline                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502   RGB-D      \u2502     \u2502   Isaac ROS  \u2502     \u2502   NITROS     \u2502   \u2502\n\u2502   \u2502   Camera     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Container  \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   Pipeline   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                    \u2502            \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                  NITROS Layer                  \u2502          \u2502\u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\u2502\n\u2502   \u2502  \u2502  Rectify    \u2502 \u2502  DetectNet  \u2502 \u2502    Depth           \u2502 \u2502\u2502\n\u2502   \u2502  \u2502  (GPU)      \u2502 \u2502  (TensorRT) \u2502 \u2502    Fusion          \u2502 \u2502\u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502             \u2502               \u2502                  \u2502              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                    Fusion Node                           \u2502\u2502\n\u2502   \u2502  \u2022 2D\u21923D projection  \u2022 Multi-object tracking            \u2502\u2502\n\u2502   \u2502  \u2022 Temporal filtering \u2022 Scene graph output              \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                              \u2502                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502                   ROS 2 Interface                        \u2502\u2502\n\u2502   \u2502  /detections_3d  /tracked_objects  /scene_graph         \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requirements-2",children:"Requirements"}),"\n",(0,r.jsx)(n.h4,{id:"core-pipeline-requirements",children:"Core Pipeline Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Camera Input Processing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Support Intel RealSense D435i (or simulated equivalent)"}),"\n",(0,r.jsx)(n.li,{children:"RGB image at 640x480, 30 Hz minimum"}),"\n",(0,r.jsx)(n.li,{children:"Depth-aligned image for 3D projection"}),"\n",(0,r.jsx)(n.li,{children:"Proper camera intrinsic calibration"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Object Detection"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deploy PeopleNet or custom detection model"}),"\n",(0,r.jsx)(n.li,{children:"TensorRT optimization for inference"}),"\n",(0,r.jsx)(n.li,{children:"Detection output at 20+ FPS on RTX 2070+"}),"\n",(0,r.jsx)(n.li,{children:"Support for at least 3 object classes"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"3D Localization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Project 2D detections to 3D using depth"}),"\n",(0,r.jsx)(n.li,{children:"Output bounding boxes in camera frame"}),"\n",(0,r.jsx)(n.li,{children:"Transform to robot base_link frame"}),"\n",(0,r.jsx)(n.li,{children:"Handle missing depth gracefully"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Object Tracking"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Persistent IDs across frames"}),"\n",(0,r.jsx)(n.li,{children:"Kalman filter-based state estimation"}),"\n",(0,r.jsx)(n.li,{children:"Handle occlusions (3+ frame memory)"}),"\n",(0,r.jsx)(n.li,{children:"Velocity estimation for tracked objects"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"performance-requirements",children:"Performance Requirements"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Metric"}),(0,r.jsx)(n.th,{children:"Target"}),(0,r.jsx)(n.th,{children:"Minimum"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"End-to-end latency"}),(0,r.jsx)(n.td,{children:"< 50ms"}),(0,r.jsx)(n.td,{children:"< 100ms"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Detection rate"}),(0,r.jsx)(n.td,{children:"30 FPS"}),(0,r.jsx)(n.td,{children:"20 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Tracking accuracy"}),(0,r.jsx)(n.td,{children:"> 90%"}),(0,r.jsx)(n.td,{children:"> 80%"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"GPU memory"}),(0,r.jsx)(n.td,{children:"< 4GB"}),(0,r.jsx)(n.td,{children:"< 6GB"})]})]})]}),"\n",(0,r.jsx)(n.h4,{id:"integration-requirements-1",children:"Integration Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"ROS 2 Topics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/color/image_raw"})," - Input RGB"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/depth/image_rect"})," - Input depth"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/perception/detections_2d"})," - 2D detections"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/perception/detections_3d"})," - 3D detections"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/perception/tracked_objects"})," - Tracked objects with IDs"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Services"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/perception/reset_tracking"})," - Clear all tracks"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/perception/get_scene"})," - Return current scene graph"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Launch Configuration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Single launch file for complete pipeline"}),"\n",(0,r.jsxs)(n.li,{children:["Support ",(0,r.jsx)(n.code,{children:"simulation:=true"})," for testing"]}),"\n",(0,r.jsx)(n.li,{children:"Configurable detection confidence threshold"}),"\n",(0,r.jsx)(n.li,{children:"Enable/disable tracking mode"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deliverables-2",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Isaac ROS Docker workspace setup"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Detection model deployment (TensorRT engine)"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Fusion node (Python or C++) for 3D localization"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Tracking node with Kalman filter implementation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Launch files and configuration"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","RViz2 visualization config showing detections"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Performance benchmark results"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","README with setup and usage instructions"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Video demonstration (2-3 minutes)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rubric-2",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Detection Pipeline"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"DetectNet running with TensorRT, 20+ FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"3D Localization"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Accurate projection, proper transforms"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Object Tracking"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Persistent IDs, handles occlusions"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Performance"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Meets latency and throughput targets"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Integration"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Clean ROS 2 interfaces, launch files"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Documentation"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Clear setup, architecture diagram"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Bonus Features"})}),(0,r.jsx)(n.td,{children:"+15"}),(0,r.jsx)(n.td,{children:"Custom model, scene graph, Isaac Sim integration"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Total"}),": 100 points (115 with bonus)\n",(0,r.jsx)(n.strong,{children:"Passing"}),": 70 points"]}),"\n",(0,r.jsx)(n.h3,{id:"suggested-approach-2",children:"Suggested Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 1-2"}),": Set up Isaac ROS Docker environment"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 3-4"}),": Deploy and test DetectNet"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 5-6"}),": Implement 3D projection and fusion"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 7-8"}),": Add object tracking"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 9-10"}),": Optimize, benchmark, and document"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"extension-challenges-2",children:"Extension Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Train custom detection model for specific objects"}),"\n",(0,r.jsx)(n.li,{children:"Add semantic segmentation for scene understanding"}),"\n",(0,r.jsx)(n.li,{children:"Implement multi-camera fusion"}),"\n",(0,r.jsx)(n.li,{children:"Create Isaac Sim test environment"}),"\n",(0,r.jsx)(n.li,{children:"Build scene graph with spatial relations"}),"\n",(0,r.jsx)(n.li,{children:"Deploy on Jetson for embedded testing"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"starter-code-2",children:"Starter Code"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="perception_node.py"',children:'"""Isaac ROS perception pipeline node."""\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom vision_msgs.msg import Detection3DArray, Detection3D\nfrom tf2_ros import Buffer, TransformListener\nimport numpy as np\n\nclass PerceptionNode(Node):\n    """GPU-accelerated perception pipeline."""\n\n    def __init__(self):\n        super().__init__(\'perception_pipeline\')\n\n        # Parameters\n        self.declare_parameter(\'confidence_threshold\', 0.5)\n        self.declare_parameter(\'tracking_enabled\', True)\n\n        # TF2 for coordinate transforms\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Camera intrinsics (populated from CameraInfo)\n        self.camera_matrix = None\n\n        # Subscribers\n        self.detection_sub = self.create_subscription(\n            Detection2DArray, \'/detectnet/detections\',\n            self.detection_callback, 10\n        )\n        self.depth_sub = self.create_subscription(\n            Image, \'/camera/depth/image_rect\',\n            self.depth_callback, 10\n        )\n        self.info_sub = self.create_subscription(\n            CameraInfo, \'/camera/color/camera_info\',\n            self.info_callback, 10\n        )\n\n        # Publishers\n        self.detection_3d_pub = self.create_publisher(\n            Detection3DArray, \'/perception/detections_3d\', 10\n        )\n\n        # State\n        self.latest_depth = None\n        self.tracker = None  # TODO: Initialize tracker\n\n        self.get_logger().info(\'Perception node initialized\')\n\n    def info_callback(self, msg):\n        """Store camera intrinsics."""\n        self.camera_matrix = np.array(msg.k).reshape(3, 3)\n\n    def depth_callback(self, msg):\n        """Store latest depth image."""\n        # TODO: Convert to numpy array\n        pass\n\n    def detection_callback(self, msg):\n        """Process 2D detections and project to 3D."""\n        if self.camera_matrix is None or self.latest_depth is None:\n            return\n\n        detections_3d = Detection3DArray()\n        detections_3d.header = msg.header\n\n        for det_2d in msg.detections:\n            # TODO: Project 2D bbox center to 3D using depth\n            # TODO: Create Detection3D message\n            # TODO: Transform to base_link frame\n            pass\n\n        # TODO: Update tracker with detections\n\n        self.detection_3d_pub.publish(detections_3d)\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = PerceptionNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",metastring:'title="perception_launch_config.yaml"',children:'/**:\n  ros__parameters:\n    # Detection\n    confidence_threshold: 0.5\n    max_detections: 50\n\n    # Tracking\n    tracking_enabled: true\n    max_track_age: 5\n    min_track_hits: 3\n\n    # 3D Localization\n    depth_scale: 0.001  # mm to meters\n    max_depth: 5.0\n    min_depth: 0.3\n\n    # Frame IDs\n    camera_frame: "camera_color_optical_frame"\n    base_frame: "base_link"\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"project-4-vla-demo-system",children:"Project 4: VLA Demo System"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Module"}),": 4 - Vision-Language-Action Models"]}),"\n",(0,r.jsx)(n.h3,{id:"overview-3",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Implement a demonstration system that uses vision-language models to interpret natural language commands and generate robot actions based on visual scene understanding. This project will help you understand how state-of-the-art models like RT-2 and Octo combine perception, language, and action."}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives-3",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this project, you will demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Integration of vision and language models for robotics"}),"\n",(0,r.jsx)(n.li,{children:"Understanding of action tokenization and execution"}),"\n",(0,r.jsx)(n.li,{children:"End-to-end inference pipeline implementation"}),"\n",(0,r.jsx)(n.li,{children:"Evaluation of model performance on robotic tasks"}),"\n",(0,r.jsx)(n.li,{children:"Troubleshooting of complex AI systems"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"system-architecture-3",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    VLA Demo System                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502   Camera    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   VLA Model      \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  Action     \u2502 \u2502\n\u2502   \u2502   (Image)   \u2502     \u2502 (Vision-Language \u2502     \u2502  Decoder    \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502  -Action)        \u2502     \u2502             \u2502 \u2502\n\u2502                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                \u2502                        \u2502      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502                        \u25bc      \u2502\n\u2502   \u2502  Natural        \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502   \u2502  Language       \u2502          \u2502               \u2502  Robot       \u2502\u2502\n\u2502   \u2502  Command        \u2502          \u2502               \u2502  Execution   \u2502\u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502               \u2502    Node      \u2502\u2502\n\u2502                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524              \u2502\u2502\n\u2502                                                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requirements-3",children:"Requirements"}),"\n",(0,r.jsx)(n.h4,{id:"core-pipeline-requirements-1",children:"Core Pipeline Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Vision Input Processing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Support RGB camera input (640x480 minimum)"}),"\n",(0,r.jsx)(n.li,{children:"Preprocess images for VLA model input"}),"\n",(0,r.jsx)(n.li,{children:"Handle variable lighting conditions"}),"\n",(0,r.jsx)(n.li,{children:"Integrate with ROS 2 image transport"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Language Processing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Accept natural language commands via text input"}),"\n",(0,r.jsx)(n.li,{children:"Parse and interpret command intent"}),"\n",(0,r.jsx)(n.li,{children:"Map language to potential robot actions"}),"\n",(0,r.jsx)(n.li,{children:"Handle ambiguous or complex commands"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"VLA Model Integration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deploy pre-trained VLA model (RT-2, Octo, or similar)"}),"\n",(0,r.jsx)(n.li,{children:"Handle model inference efficiently"}),"\n",(0,r.jsx)(n.li,{children:"Convert model outputs to robot actions"}),"\n",(0,r.jsx)(n.li,{children:"Implement appropriate action discretization"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Action Execution"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Convert predicted actions to robot control commands"}),"\n",(0,r.jsx)(n.li,{children:"Handle multiple action modalities (navigation, manipulation)"}),"\n",(0,r.jsx)(n.li,{children:"Implement safety checks and validation"}),"\n",(0,r.jsx)(n.li,{children:"Provide feedback on action success/failure"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"integration-requirements-2",children:"Integration Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"ROS 2 Topics"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/vla/command"})," - Natural language commands"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/camera/image_raw"})," - Input images"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/vla/actions"})," - Predicted robot actions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"/vla/status"})," - System status and feedback"]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Performance Requirements"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"End-to-end latency under 2 seconds for inference"}),"\n",(0,r.jsx)(n.li,{children:"Handle 1Hz command frequency minimum"}),"\n",(0,r.jsx)(n.li,{children:"GPU memory usage under 8GB (if using GPU)"}),"\n",(0,r.jsx)(n.li,{children:"CPU usage under 50% during inference"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Launch Configuration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Single launch file for complete pipeline"}),"\n",(0,r.jsxs)(n.li,{children:["Support for ",(0,r.jsx)(n.code,{children:"simulation:=true"})," parameter"]}),"\n",(0,r.jsx)(n.li,{children:"Configurable model selection"}),"\n",(0,r.jsx)(n.li,{children:"Enable/disable visualization options"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deliverables-3",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","VLA model integration with ROS 2 interface"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Image preprocessing pipeline"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Natural language command parser"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Action decoder for robot execution"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Launch files and configuration"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","RViz2 visualization config for action planning"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Performance benchmark results"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","README with setup and usage instructions"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Video demonstration (2-3 minutes)"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rubric-3",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"VLA Model Integration"})}),(0,r.jsx)(n.td,{children:"25"}),(0,r.jsx)(n.td,{children:"Successfully deployed and running VLA model"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Vision Processing"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Proper image handling and preprocessing"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Language Understanding"})}),(0,r.jsx)(n.td,{children:"20"}),(0,r.jsx)(n.td,{children:"Accurate command interpretation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Action Execution"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Actions properly converted to robot commands"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Performance"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Meets latency and resource requirements"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Integration"})}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"Clean ROS 2 interfaces, launch files"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Documentation"})}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"Clear setup, architecture diagram"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Bonus Features"})}),(0,r.jsx)(n.td,{children:"+15"}),(0,r.jsx)(n.td,{children:"Advanced language understanding, multimodal input, etc."})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Total"}),": 100 points (115 with bonus)\n",(0,r.jsx)(n.strong,{children:"Passing"}),": 70 points"]}),"\n",(0,r.jsx)(n.h3,{id:"suggested-approach-3",children:"Suggested Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 1-2"}),": Set up VLA model environment and test inference"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 3-4"}),": Build image preprocessing pipeline"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 5-6"}),": Implement language command processing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 7-8"}),": Connect model outputs to robot actions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Days 9-10"}),": Test, integrate, and optimize performance"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"extension-challenges-3",children:"Extension Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Implement few-shot learning capabilities"}),"\n",(0,r.jsx)(n.li,{children:"Add multi-step command handling"}),"\n",(0,r.jsx)(n.li,{children:"Integrate with a real robot (not just simulation)"}),"\n",(0,r.jsx)(n.li,{children:"Add uncertainty quantification to predictions"}),"\n",(0,r.jsx)(n.li,{children:"Create a web interface for text commands"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"starter-code-structure",children:"Starter Code Structure"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="vla_demo_node.py"',children:'"""VLA Demo System node."""\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom std_msgs.msg import String\nimport numpy as np\nimport torch\n\nclass VLADemoNode(Node):\n    """Vision-Language-Action demonstration system."""\n\n    def __init__(self):\n        super().__init__(\'vla_demo_system\')\n\n        # Parameters\n        self.declare_parameter(\'model_name\', \'octo-base\')\n        self.declare_parameter(\'confidence_threshold\', 0.5)\n\n        # Subscribers\n        self.image_sub = self.create_subscription(\n            Image, \'/camera/image_raw\', self.image_callback, 10\n        )\n        self.command_sub = self.create_subscription(\n            String, \'/vla/command\', self.command_callback, 10\n        )\n\n        # Publishers\n        # TODO: Define publishers for actions and status\n\n        # Initialize VLA model\n        self.load_vla_model()\n\n        # State\n        self.current_image = None\n        self.pending_command = None\n\n        self.get_logger().info(\'VLA Demo System initialized\')\n\n    def load_vla_model(self):\n        """Load pre-trained VLA model."""\n        # TODO: Load model (Octo, RT-2, or equivalent)\n        pass\n\n    def image_callback(self, msg):\n        """Process incoming image."""\n        # TODO: Store image and perform inference if command is pending\n        pass\n\n    def command_callback(self, msg):\n        """Process incoming language command."""\n        # TODO: Store command and perform inference if image is available\n        pass\n\n    def run_vla_inference(self, image, command):\n        """Run VLA model inference."""\n        # TODO: Process image and command through VLA model\n        # TODO: Convert outputs to action space\n        pass\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = VLADemoNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-yaml",metastring:'title="vla_demo_config.yaml"',children:'/**:\n  ros__parameters:\n    # VLA Model\n    model_name: "octo-base"  # or "rt-2"\n    model_path: "/path/to/pretrained/model"\n\n    # Processing\n    image_resize: [128, 128]  # for model input\n    confidence_threshold: 0.5\n\n    # Actions\n    max_action_steps: 10\n    action_space: "discrete"  # or "continuous"\n'})}),"\n",(0,r.jsx)(n.h3,{id:"resources",children:"Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/octo-models",children:"Octo Repository"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://arxiv.org/abs/2307.15818",children:"RT-2 Paper"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://huggingface.co/papers/2310.12945",children:"VLA Models Overview"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"capstone-project",children:"Capstone Project"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"All Modules"})}),"\n",(0,r.jsx)(n.h3,{id:"overview-4",children:"Overview"}),"\n",(0,r.jsx)(n.p,{children:"Design and implement an autonomous assistant robot that combines all skills learned throughout the course. The robot should navigate an environment, perceive objects, understand natural language commands, and perform manipulation tasks in response to high-level instructions."}),"\n",(0,r.jsx)(n.h3,{id:"learning-objectives-4",children:"Learning Objectives"}),"\n",(0,r.jsx)(n.p,{children:"By completing this capstone project, you will demonstrate:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Integration of all Physical AI components into a cohesive system"}),"\n",(0,r.jsx)(n.li,{children:"End-to-end system design and implementation"}),"\n",(0,r.jsx)(n.li,{children:"Troubleshooting complex multi-component systems"}),"\n",(0,r.jsx)(n.li,{children:"Professional-level documentation and presentation"}),"\n",(0,r.jsx)(n.li,{children:"Application of AI techniques to real-world robotics problems"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"system-architecture-4",children:"System Architecture"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  Autonomous Assistant System                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                  \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                High-Level Controller                      \u2502   \u2502\n\u2502   \u2502  \u2022 Command interpretation                                \u2502   \u2502\n\u2502   \u2502  \u2022 Task planning                                         \u2502   \u2502\n\u2502   \u2502  \u2022 Behavior arbitration                                  \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                 \u2502                                                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502   VLA Command Handler     \u2502  \u2502     Navigation System       \u2502 \u2502\n\u2502   \u2502 \u2022 Natural language input  \u2502  \u2502 \u2022 Map building (SLAM)       \u2502 \u2502\n\u2502   \u2502 \u2022 Intent interpretation   \u2502  \u2502 \u2022 Path planning             \u2502 \u2502\n\u2502   \u2502 \u2022 Action sequence gen.    \u2502  \u2502 \u2022 Path following            \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                 \u2502                              \u2502                 \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502    Perception System      \u2502  \u2502    Manipulation System      \u2502 \u2502\n\u2502   \u2502 \u2022 Object detection        \u2502  \u2502 \u2022 Grasp planning            \u2502 \u2502\n\u2502   \u2502 \u2022 Scene understanding     \u2502  \u2502 \u2022 Trajectory execution      \u2502 \u2502\n\u2502   \u2502 \u2022 State estimation        \u2502  \u2502 \u2022 Pick-and-place            \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2502                                   \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502                   Robot Platform                          \u2502 \u2502\n\u2502   \u2502  \u2022 Mobile base with differential drive                    \u2502 \u2502\n\u2502   \u2502  \u2022 Manipulator arm with end-effector                      \u2502 \u2502\n\u2502   \u2502  \u2022 RGB-D camera, LiDAR, IMU                               \u2502 \u2502\n\u2502   \u2502  \u2022 ROS 2 integration                                      \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(n.h3,{id:"requirements-4",children:"Requirements"}),"\n",(0,r.jsx)(n.h4,{id:"core-system-requirements",children:"Core System Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Command Processing"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Accept high-level natural language commands"}),"\n",(0,r.jsx)(n.li,{children:"Parse and decompose complex tasks"}),"\n",(0,r.jsx)(n.li,{children:"Generate executable action sequences"}),"\n",(0,r.jsx)(n.li,{children:"Handle command clarification queries"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Autonomous Navigation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Build map of environment (SLAM)"}),"\n",(0,r.jsx)(n.li,{children:"Plan paths to specified locations"}),"\n",(0,r.jsx)(n.li,{children:"Navigate while avoiding obstacles"}),"\n",(0,r.jsx)(n.li,{children:"Handle dynamic obstacles if present"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Perception System"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Detect and identify objects in the environment"}),"\n",(0,r.jsx)(n.li,{children:"Estimate object poses for manipulation"}),"\n",(0,r.jsx)(n.li,{children:"Track objects and environment changes"}),"\n",(0,r.jsx)(n.li,{children:"Integrate multiple sensor modalities"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Manipulation Capabilities"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Execute pick-and-place operations"}),"\n",(0,r.jsx)(n.li,{children:"Handle objects of various shapes/sizes"}),"\n",(0,r.jsx)(n.li,{children:"Plan collision-free trajectories"}),"\n",(0,r.jsx)(n.li,{children:"Execute precise manipulations"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"integration-requirements-3",children:"Integration Requirements"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"ROS 2 Architecture"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Modular node design with clear interfaces"}),"\n",(0,r.jsx)(n.li,{children:"Proper error handling and recovery"}),"\n",(0,r.jsx)(n.li,{children:"Appropriate message types and topics"}),"\n",(0,r.jsx)(n.li,{children:"Efficient state management"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Performance Requirements"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Complete task within 10 minutes average"}),"\n",(0,r.jsx)(n.li,{children:"Navigation success rate > 90%"}),"\n",(0,r.jsx)(n.li,{children:"Object manipulation success rate > 75%"}),"\n",(0,r.jsx)(n.li,{children:"System uptime > 95% during operation"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Safety & Robustness"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Emergency stop functionality"}),"\n",(0,r.jsx)(n.li,{children:"Collision avoidance during navigation and manipulation"}),"\n",(0,r.jsx)(n.li,{children:"Graceful degradation when components fail"}),"\n",(0,r.jsx)(n.li,{children:"Safe operation limits enforced"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"deliverables-4",children:"Deliverables"}),"\n",(0,r.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Complete integrated robot system"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","High-level command processing module"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Autonomous navigation with SLAM"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Object perception and detection"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Manipulation system with pick/place"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","System integration and orchestration"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Comprehensive documentation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","10-minute technical presentation"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Video demonstration of complete system"]}),"\n",(0,r.jsxs)(n.li,{className:"task-list-item",children:[(0,r.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Source code with unit tests"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"rubric-4",children:"Rubric"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Criterion"}),(0,r.jsx)(n.th,{children:"Points"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"System Integration"})}),(0,r.jsx)(n.td,{children:"25"}),(0,r.jsx)(n.td,{children:"All components work together seamlessly"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Command Processing"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Natural language commands interpreted and executed"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Navigation"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Successful autonomous navigation and mapping"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Perception"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Accurate object detection and state estimation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Manipulation"})}),(0,r.jsx)(n.td,{children:"15"}),(0,r.jsx)(n.td,{children:"Successful pick-and-place operations"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Performance"})}),(0,r.jsx)(n.td,{children:"10"}),(0,r.jsx)(n.td,{children:"Meets specified performance requirements"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Documentation"})}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"Complete technical documentation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Presentation"})}),(0,r.jsx)(n.td,{children:"5"}),(0,r.jsx)(n.td,{children:"Clear explanation of design and implementation"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Bonus Features"})}),(0,r.jsx)(n.td,{children:"+10"}),(0,r.jsx)(n.td,{children:"Advanced capabilities, exceptional implementation"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Total"}),": 105 points (115 with bonus)\n",(0,r.jsx)(n.strong,{children:"Passing"}),": 75 points"]}),"\n",(0,r.jsx)(n.h3,{id:"suggested-approach-4",children:"Suggested Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 1"}),": System architecture design and component integration plan"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 2"}),": Implement basic command processing and navigation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 3"}),": Add perception and manipulation capabilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 4"}),": Integrate components and optimize system performance"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Week 5"}),": Final testing, documentation, and presentation preparation"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"extension-challenges-4",children:"Extension Challenges"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Multi-object manipulation sequences"}),"\n",(0,r.jsx)(n.li,{children:"Human-robot interaction and collaboration"}),"\n",(0,r.jsx)(n.li,{children:"Learning from demonstration"}),"\n",(0,r.jsx)(n.li,{children:"Adaptive behavior based on environment"}),"\n",(0,r.jsx)(n.li,{children:"Integration with cloud services or external APIs"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"architecture-considerations",children:"Architecture Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use behavior trees or state machines for task orchestration"}),"\n",(0,r.jsx)(n.li,{children:"Implement proper error handling and recovery mechanisms"}),"\n",(0,r.jsx)(n.li,{children:"Design modular components that can be independently tested"}),"\n",(0,r.jsx)(n.li,{children:"Plan for resource constraints on robot computer"}),"\n",(0,r.jsx)(n.li,{children:"Consider real-time performance requirements"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"resources-1",children:"Resources"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://navigation.ros.org/",children:"Navigation2 Documentation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://moveit.ros.org/",children:"MoveIt! Motion Planning"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://www.cs.unc.edu/~jcarback/publications/ICRA14_bts.pdf",children:"Behavior Trees in Robotics"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://design.ros2.org/",children:"ROS 2 Design"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"submission-guidelines",children:"Submission Guidelines"}),"\n",(0,r.jsx)(n.h3,{id:"format",children:"Format"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Submit via GitHub repository"}),"\n",(0,r.jsx)(n.li,{children:"Include all source code, configuration files, and documentation"}),"\n",(0,r.jsx)(n.li,{children:"Provide clear build and run instructions"}),"\n",(0,r.jsx)(n.li,{children:"Include video demonstration (2-5 minutes)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"grading-timeline",children:"Grading Timeline"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Projects submitted by deadline: Full credit eligible"}),"\n",(0,r.jsx)(n.li,{children:"Up to 1 week late: Maximum 90% credit"}),"\n",(0,r.jsx)(n.li,{children:"Up to 2 weeks late: Maximum 70% credit"}),"\n",(0,r.jsx)(n.li,{children:"Beyond 2 weeks: Not accepted"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"academic-integrity",children:"Academic Integrity"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"All code must be your own or properly attributed"}),"\n",(0,r.jsx)(n.li,{children:"Collaboration is encouraged for learning, not copying"}),"\n",(0,r.jsx)(n.li,{children:"Use of AI assistants must be disclosed"}),"\n",(0,r.jsx)(n.li,{children:"External libraries and references must be cited"}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(a,{...e})}):a(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>c});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);