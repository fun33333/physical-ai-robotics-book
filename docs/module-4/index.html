<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-4/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Module 4: Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics Book</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://fun33333.github.io/physical-ai-robotics-book/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://fun33333.github.io/physical-ai-robotics-book/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://fun33333.github.io/physical-ai-robotics-book/docs/module-4/"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Module 4: Vision-Language-Action (VLA) | Physical AI &amp; Humanoid Robotics Book"><meta data-rh="true" name="description" content="Build end-to-end systems that connect vision, language understanding, and robot action generation."><meta data-rh="true" property="og:description" content="Build end-to-end systems that connect vision, language understanding, and robot action generation."><link data-rh="true" rel="icon" href="/physical-ai-robotics-book/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://fun33333.github.io/physical-ai-robotics-book/docs/module-4/"><link data-rh="true" rel="alternate" href="https://fun33333.github.io/physical-ai-robotics-book/docs/module-4/" hreflang="en"><link data-rh="true" rel="alternate" href="https://fun33333.github.io/physical-ai-robotics-book/docs/module-4/" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Module 4: Vision-Language-Action (VLA)","item":"https://fun33333.github.io/physical-ai-robotics-book/docs/module-4/"}]}</script><link rel="alternate" type="application/rss+xml" href="/physical-ai-robotics-book/blog/rss.xml" title="Physical AI &amp; Humanoid Robotics Book RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/physical-ai-robotics-book/blog/atom.xml" title="Physical AI &amp; Humanoid Robotics Book Atom Feed"><link rel="stylesheet" href="/physical-ai-robotics-book/assets/css/styles.9c53a5ce.css">
<script src="/physical-ai-robotics-book/assets/js/runtime~main.758d8e59.js" defer="defer"></script>
<script src="/physical-ai-robotics-book/assets/js/main.7777d2dc.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/physical-ai-robotics-book/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/physical-ai-robotics-book/"><div class="navbar__logo"><img src="/physical-ai-robotics-book/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/physical-ai-robotics-book/img/logo.svg" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Physical AI Book</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/physical-ai-robotics-book/docs/intro/">Docs</a><a class="navbar__item navbar__link" href="/physical-ai-robotics-book/blog/">Blog</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/fun33333/physical-ai-robotics-book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="true" href="/physical-ai-robotics-book/docs/intro/"><span title="Introduction" class="categoryLinkLabel_W154">Introduction</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/intro/"><span title="Introduction to Physical AI" class="linkLabel_WmDU">Introduction to Physical AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/why-physical-ai/"><span title="Why Physical AI?" class="linkLabel_WmDU">Why Physical AI?</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/learning-outcomes/"><span title="Learning Outcomes" class="linkLabel_WmDU">Learning Outcomes</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/module-1/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/module-2/"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/module-3/"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaac)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaac)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/physical-ai-robotics-book/docs/module-4/"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/"><span title="Module 4: Vision-Language-Action (VLA)" class="linkLabel_WmDU">Module 4: Vision-Language-Action (VLA)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/vla-foundations/"><span title="VLA Foundations" class="linkLabel_WmDU">VLA Foundations</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/vision-models/"><span title="Vision Models for Robotics" class="linkLabel_WmDU">Vision Models for Robotics</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/language-integration/"><span title="Language Model Integration" class="linkLabel_WmDU">Language Model Integration</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/action-generation/"><span title="Action Generation" class="linkLabel_WmDU">Action Generation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/physical-ai-robotics-book/docs/module-4/end-to-end-vla/"><span title="End-to-End VLA Systems" class="linkLabel_WmDU">End-to-End VLA Systems</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/hardware/"><span title="Hardware Guide" class="categoryLinkLabel_W154">Hardware Guide</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/weekly-breakdown/"><span title="Weekly Breakdown" class="categoryLinkLabel_W154">Weekly Breakdown</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/physical-ai-robotics-book/docs/assessments/"><span title="Assessments" class="categoryLinkLabel_W154">Assessments</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/physical-ai-robotics-book/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Module 4: Vision-Language-Action (VLA)</h1></header>
<p>Vision-Language-Action (VLA) models represent the frontier of robot intelligence, enabling systems that understand natural language commands, perceive their environment through vision, and generate appropriate physical actions. This module explores how foundation models are revolutionizing robotics.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-overview">Module Overview<a href="#module-overview" class="hash-link" aria-label="Direct link to Module Overview" title="Direct link to Module Overview" translate="no">​</a></h2>
<p>VLA systems bridge the gap between foundation models trained on internet-scale data and the physical world of robotics. By leveraging pre-trained vision and language models, robots can generalize to new tasks, understand nuanced instructions, and adapt to novel situations with minimal task-specific training.</p>
<p>This module takes you from the theoretical foundations through practical implementation of VLA components, preparing you to work on the cutting edge of Physical AI.</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="what-youll-learn">What You&#x27;ll Learn<a href="#what-youll-learn" class="hash-link" aria-label="Direct link to What You&#x27;ll Learn" title="Direct link to What You&#x27;ll Learn" translate="no">​</a></h3>
<table><thead><tr><th>Chapter</th><th>Focus</th><th>Key Skills</th></tr></thead><tbody><tr><td><a class="" href="/physical-ai-robotics-book/docs/module-4/vla-foundations/">VLA Foundations</a></td><td>Architecture overview</td><td>Understanding multimodal transformers</td></tr><tr><td><a class="" href="/physical-ai-robotics-book/docs/module-4/vision-models/">Vision Models</a></td><td>Visual perception</td><td>ViT, CLIP, feature extraction</td></tr><tr><td><a class="" href="/physical-ai-robotics-book/docs/module-4/language-integration/">Language Integration</a></td><td>LLM for robotics</td><td>Instruction following, planning</td></tr><tr><td><a class="" href="/physical-ai-robotics-book/docs/module-4/action-generation/">Action Generation</a></td><td>Policy architectures</td><td>Diffusion policies, action tokenization</td></tr><tr><td><a class="" href="/physical-ai-robotics-book/docs/module-4/end-to-end-vla/">End-to-End VLA</a></td><td>Complete systems</td><td>RT-2, Octo, OpenVLA</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h3>
<p>Before starting this module, ensure you have:</p>
<ul>
<li class="">Completed <a class="" href="/physical-ai-robotics-book/docs/module-1/">Module 1: ROS 2</a> (robot control basics)</li>
<li class="">Completed <a class="" href="/physical-ai-robotics-book/docs/module-3/">Module 3: Isaac Platform</a> (GPU computing)</li>
<li class="">Understanding of neural networks (CNNs, transformers)</li>
<li class="">PyTorch proficiency</li>
<li class="">Basic familiarity with attention mechanisms</li>
</ul>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>Advanced Content</div><div class="admonitionContent_BuS1"><p>This module covers research-level material. Some concepts are from papers published in 2023-2024. Expect to engage with academic literature and experimental code.</p></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-vla-revolution">The VLA Revolution<a href="#the-vla-revolution" class="hash-link" aria-label="Direct link to The VLA Revolution" title="Direct link to The VLA Revolution" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="from-separate-models-to-unified-systems">From Separate Models to Unified Systems<a href="#from-separate-models-to-unified-systems" class="hash-link" aria-label="Direct link to From Separate Models to Unified Systems" title="Direct link to From Separate Models to Unified Systems" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">┌─────────────────────────────────────────────────────────────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│              Evolution of Robot Intelligence                      │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─────────────────────────────────────────────────────────────────┤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   Traditional Robotics (2000-2015)                              │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ┌─────────┐    ┌─────────┐    ┌─────────┐                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │ Vision  │ →  │ Planning│ →  │ Control │   Separate         │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │ (CV)    │    │ (PDDL)  │    │ (PID)   │   components       │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └─────────┘    └─────────┘    └─────────┘                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   Learning-Based (2015-2020)                                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ┌─────────┐    ┌─────────────────────────┐                   │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │ Vision  │ →  │ End-to-End Policy (RL)  │   Vision-to-      │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │ (CNN)   │    │ (MLP/RNN)               │   action          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └─────────┘    └─────────────────────────┘                   │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   VLA Era (2022-Present)                                        │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ┌─────────────────────────────────────────────────────────┐  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │                 VLA Model (Transformer)                   │  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │  Vision Encoder + Language Model + Action Decoder        │  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │                                                           │  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │  &quot;Pick up the red cup&quot; → [joint angles, gripper state]   │  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └─────────────────────────────────────────────────────────┘  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─────────────────────────────────────────────────────────────────┘</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="why-vla-matters">Why VLA Matters<a href="#why-vla-matters" class="hash-link" aria-label="Direct link to Why VLA Matters" title="Direct link to Why VLA Matters" translate="no">​</a></h3>
<table><thead><tr><th>Capability</th><th>Traditional</th><th>VLA</th></tr></thead><tbody><tr><td><strong>New tasks</strong></td><td>Requires reprogramming</td><td>Natural language instruction</td></tr><tr><td><strong>Generalization</strong></td><td>Task-specific</td><td>Broad transfer</td></tr><tr><td><strong>Scene understanding</strong></td><td>Hand-crafted features</td><td>Semantic comprehension</td></tr><tr><td><strong>Reasoning</strong></td><td>Fixed rules</td><td>Common-sense reasoning</td></tr><tr><td><strong>Data efficiency</strong></td><td>Millions of robot demos</td><td>Leverages internet data</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="the-vla-architecture">The VLA Architecture<a href="#the-vla-architecture" class="hash-link" aria-label="Direct link to The VLA Architecture" title="Direct link to The VLA Architecture" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">┌─────────────────────────────────────────────────────────────────┐</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    VLA Model Architecture                        │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├─────────────────────────────────────────────────────────────────┤</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   Inputs:                                                        │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ┌──────────────┐  ┌──────────────────────┐  ┌──────────────┐ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   Images     │  │  Language Command    │  │ Robot State  │ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │  (RGB/Depth) │  │ &quot;Pick up the apple&quot;  │  │  (joints)    │ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └──────┬───────┘  └──────────┬───────────┘  └──────┬───────┘ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│          │                     │                     │          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   ┌──────▼───────┐  ┌──────────▼───────────┐  ┌──────▼───────┐ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   Vision     │  │     Language         │  │   State      │ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   Encoder    │  │     Encoder          │  │   Encoder    │ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   │   (ViT)      │  │   (Transformer)      │  │   (MLP)      │ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   └──────┬───────┘  └──────────┬───────────┘  └──────┬───────┘ │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│          │                     │                     │          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│          └─────────────────────┼─────────────────────┘          │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                │                                 │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    ┌───────────▼───────────┐                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    Cross-Modal        │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    Fusion Layer       │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    (Attention)        │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    └───────────┬───────────┘                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                │                                 │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    ┌───────────▼───────────┐                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    Action Decoder     │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    (Transformer)      │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    └───────────┬───────────┘                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                │                                 │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│   Output:          ┌───────────▼───────────┐                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │   Robot Actions       │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │   [Δx, Δy, Δz, Δrpy,  │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    │    gripper]           │                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                    └───────────────────────┘                    │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">│                                                                  │</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└─────────────────────────────────────────────────────────────────┘</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="learning-path">Learning Path<a href="#learning-path" class="hash-link" aria-label="Direct link to Learning Path" title="Direct link to Learning Path" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="week-1-foundations">Week 1: Foundations<a href="#week-1-foundations" class="hash-link" aria-label="Direct link to Week 1: Foundations" title="Direct link to Week 1: Foundations" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Day 1-2: VLA Foundations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Transformer architecture review</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Multimodal learning concepts</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Key papers: RT-2, PaLM-E</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Day 3-4: Vision Models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Vision Transformer (ViT)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── CLIP and contrastive learning</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Feature extraction for robotics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Day 5-7: Integration Lab</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Set up inference environment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Run pre-trained VLA model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Analyze model outputs</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="week-2-components">Week 2: Components<a href="#week-2-components" class="hash-link" aria-label="Direct link to Week 2: Components" title="Direct link to Week 2: Components" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Day 1-2: Language Integration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── LLM architectures for robotics</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Instruction tokenization</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Prompt engineering</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Day 3-4: Action Generation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Action representations</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Diffusion policies</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Safety constraints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Day 5-7: End-to-End Systems</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Complete VLA architectures</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">├── Training strategies</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">└── Deployment considerations</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="module-project-vla-demo-system">Module Project: VLA Demo System<a href="#module-project-vla-demo-system" class="hash-link" aria-label="Direct link to Module Project: VLA Demo System" title="Direct link to Module Project: VLA Demo System" translate="no">​</a></h2>
<p>The capstone project for this module is building a language-conditioned robot control system:</p>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="project-overview">Project Overview<a href="#project-overview" class="hash-link" aria-label="Direct link to Project Overview" title="Direct link to Project Overview" translate="no">​</a></h3>
<p>Build a system that:</p>
<ol>
<li class="">Accepts natural language commands</li>
<li class="">Processes camera images of the scene</li>
<li class="">Generates robot actions to accomplish the task</li>
<li class="">Provides feedback on action execution</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="deliverables">Deliverables<a href="#deliverables" class="hash-link" aria-label="Direct link to Deliverables" title="Direct link to Deliverables" translate="no">​</a></h3>
<ul>
<li class="">VLA inference pipeline with pre-trained model</li>
<li class="">ROS 2 integration for robot control</li>
<li class="">Natural language interface</li>
<li class="">Visualization of model attention/decisions</li>
<li class="">Documentation and demo video</li>
</ul>
<p>See <a class="" href="/physical-ai-robotics-book/docs/assessments/projects/#project-4-vla-demo-system">Project 4: VLA Demo System</a> for full requirements.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-concepts-preview">Key Concepts Preview<a href="#key-concepts-preview" class="hash-link" aria-label="Direct link to Key Concepts Preview" title="Direct link to Key Concepts Preview" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="concepts-youll-master">Concepts You&#x27;ll Master<a href="#concepts-youll-master" class="hash-link" aria-label="Direct link to Concepts You&#x27;ll Master" title="Direct link to Concepts You&#x27;ll Master" translate="no">​</a></h3>
<table><thead><tr><th>Concept</th><th>Description</th><th>Applied In</th></tr></thead><tbody><tr><td><strong>Vision Transformer (ViT)</strong></td><td>Patch-based image processing</td><td>Vision encoding</td></tr><tr><td><strong>Cross-Modal Attention</strong></td><td>Fusing vision and language</td><td>Multimodal fusion</td></tr><tr><td><strong>Action Tokenization</strong></td><td>Discretizing continuous actions</td><td>Action generation</td></tr><tr><td><strong>Diffusion Policy</strong></td><td>Denoising for action generation</td><td>Smooth trajectories</td></tr><tr><td><strong>Behavioral Cloning</strong></td><td>Learning from demonstrations</td><td>Training VLA</td></tr><tr><td><strong>Prompt Engineering</strong></td><td>Crafting effective instructions</td><td>Language interface</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="landmark-systems">Landmark Systems<a href="#landmark-systems" class="hash-link" aria-label="Direct link to Landmark Systems" title="Direct link to Landmark Systems" translate="no">​</a></h3>
<table><thead><tr><th>System</th><th>Organization</th><th>Key Innovation</th></tr></thead><tbody><tr><td><strong>RT-2</strong></td><td>Google DeepMind</td><td>Vision-language-action transformer</td></tr><tr><td><strong>PaLM-E</strong></td><td>Google</td><td>Embodied language model</td></tr><tr><td><strong>Octo</strong></td><td>Berkeley</td><td>Open-source generalist policy</td></tr><tr><td><strong>OpenVLA</strong></td><td>Stanford/Berkeley</td><td>Open weights, fine-tunable</td></tr><tr><td><strong>RoboFlamingo</strong></td><td>ByteDance</td><td>Efficient adaptation</td></tr></tbody></table>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="hardware-requirements">Hardware Requirements<a href="#hardware-requirements" class="hash-link" aria-label="Direct link to Hardware Requirements" title="Direct link to Hardware Requirements" translate="no">​</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-inference">For Inference<a href="#for-inference" class="hash-link" aria-label="Direct link to For Inference" title="Direct link to For Inference" translate="no">​</a></h3>
<table><thead><tr><th>Component</th><th>Requirement</th><th>Notes</th></tr></thead><tbody><tr><td>GPU</td><td>RTX 3060 / 8GB VRAM</td><td>Minimum for small models</td></tr><tr><td>CPU</td><td>8 cores</td><td>Data preprocessing</td></tr><tr><td>RAM</td><td>32GB</td><td>Model loading</td></tr><tr><td>Storage</td><td>50GB</td><td>Model weights</td></tr></tbody></table>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="for-trainingfine-tuning">For Training/Fine-tuning<a href="#for-trainingfine-tuning" class="hash-link" aria-label="Direct link to For Training/Fine-tuning" title="Direct link to For Training/Fine-tuning" translate="no">​</a></h3>
<table><thead><tr><th>Component</th><th>Requirement</th><th>Notes</th></tr></thead><tbody><tr><td>GPU</td><td>RTX 4090 / A100</td><td>24GB+ VRAM recommended</td></tr><tr><td>CPU</td><td>16+ cores</td><td>Data loading</td></tr><tr><td>RAM</td><td>64GB+</td><td>Batch processing</td></tr><tr><td>Storage</td><td>500GB+ NVMe</td><td>Datasets and checkpoints</td></tr></tbody></table>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>Cloud Alternative</div><div class="admonitionContent_BuS1"><p>VLA training is resource-intensive. Consider Lambda Labs or RunPod with A100 GPUs for training experiments. Inference can run on consumer hardware.</p></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="getting-started-checklist">Getting Started Checklist<a href="#getting-started-checklist" class="hash-link" aria-label="Direct link to Getting Started Checklist" title="Direct link to Getting Started Checklist" translate="no">​</a></h2>
<p>Before diving into the chapters:</p>
<ul class="contains-task-list containsTaskList_mC6p">
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Review transformer architecture basics</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Install PyTorch with CUDA support</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Set up Hugging Face account for model access</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Clone example repositories</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Allocate 50GB+ storage for model weights</li>
<li class="task-list-item"><input type="checkbox" disabled=""> <!-- -->Review attention mechanism fundamentals</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="quick-environment-setup">Quick Environment Setup<a href="#quick-environment-setup" class="hash-link" aria-label="Direct link to Quick Environment Setup" title="Direct link to Quick Environment Setup" translate="no">​</a></h3>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain"># Create VLA environment</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda create -n vla python=3.10</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">conda activate vla</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install PyTorch with CUDA</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Install transformers and robotics libraries</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install transformers accelerate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install robomimic diffusers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Verify GPU access</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">python -c &quot;import torch; print(f&#x27;CUDA: {torch.cuda.is_available()}&#x27;)&quot;</span><br></span></code></pre></div></div>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="summary">Summary<a href="#summary" class="hash-link" aria-label="Direct link to Summary" title="Direct link to Summary" translate="no">​</a></h2>
<p>Module 4 introduces Vision-Language-Action models—the cutting edge of robot intelligence:</p>
<ul>
<li class=""><strong>VLA Foundations</strong>: Understanding multimodal transformer architectures</li>
<li class=""><strong>Vision Models</strong>: Leveraging pre-trained vision encoders</li>
<li class=""><strong>Language Integration</strong>: Connecting LLMs to robot control</li>
<li class=""><strong>Action Generation</strong>: From perception to physical action</li>
<li class=""><strong>End-to-End Systems</strong>: Complete VLA implementations</li>
</ul>
<p>By the end of this module, you&#x27;ll be able to:</p>
<ol>
<li class="">Explain how VLA models combine vision, language, and action</li>
<li class="">Implement inference pipelines using pre-trained VLA models</li>
<li class="">Design action representations for manipulation tasks</li>
<li class="">Evaluate VLA system performance</li>
<li class="">Deploy language-conditioned robot control systems</li>
</ol>
<p>Let&#x27;s begin with <a class="" href="/physical-ai-robotics-book/docs/module-4/vla-foundations/">VLA Foundations</a> to understand the architectural principles.</p>
<hr>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="further-reading">Further Reading<a href="#further-reading" class="hash-link" aria-label="Direct link to Further Reading" title="Direct link to Further Reading" translate="no">​</a></h2>
<ul>
<li class=""><a href="https://arxiv.org/abs/2307.15818" target="_blank" rel="noopener noreferrer" class="">RT-2 Paper</a> - Vision-Language-Action Models</li>
<li class=""><a href="https://arxiv.org/abs/2303.03378" target="_blank" rel="noopener noreferrer" class="">PaLM-E Paper</a> - Embodied Multimodal Language Model</li>
<li class=""><a href="https://octo-models.github.io/" target="_blank" rel="noopener noreferrer" class="">Octo Paper</a> - Open-Source Generalist Policy</li>
<li class=""><a href="https://openvla.github.io/" target="_blank" rel="noopener noreferrer" class="">OpenVLA</a> - Open VLA for Robot Manipulation</li>
<li class=""><a href="https://diffusion-policy.cs.columbia.edu/" target="_blank" rel="noopener noreferrer" class="">Diffusion Policy</a> - Visuomotor Policy Learning</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/fun33333/physical-ai-robotics-book/tree/main/book-website/docs/module-4/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/physical-ai-robotics-book/docs/module-3/perception-pipelines/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Perception Pipelines</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/physical-ai-robotics-book/docs/module-4/vla-foundations/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">VLA Foundations</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#module-overview" class="table-of-contents__link toc-highlight">Module Overview</a><ul><li><a href="#what-youll-learn" class="table-of-contents__link toc-highlight">What You&#39;ll Learn</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li></ul></li><li><a href="#the-vla-revolution" class="table-of-contents__link toc-highlight">The VLA Revolution</a><ul><li><a href="#from-separate-models-to-unified-systems" class="table-of-contents__link toc-highlight">From Separate Models to Unified Systems</a></li><li><a href="#why-vla-matters" class="table-of-contents__link toc-highlight">Why VLA Matters</a></li><li><a href="#the-vla-architecture" class="table-of-contents__link toc-highlight">The VLA Architecture</a></li></ul></li><li><a href="#learning-path" class="table-of-contents__link toc-highlight">Learning Path</a><ul><li><a href="#week-1-foundations" class="table-of-contents__link toc-highlight">Week 1: Foundations</a></li><li><a href="#week-2-components" class="table-of-contents__link toc-highlight">Week 2: Components</a></li></ul></li><li><a href="#module-project-vla-demo-system" class="table-of-contents__link toc-highlight">Module Project: VLA Demo System</a><ul><li><a href="#project-overview" class="table-of-contents__link toc-highlight">Project Overview</a></li><li><a href="#deliverables" class="table-of-contents__link toc-highlight">Deliverables</a></li></ul></li><li><a href="#key-concepts-preview" class="table-of-contents__link toc-highlight">Key Concepts Preview</a><ul><li><a href="#concepts-youll-master" class="table-of-contents__link toc-highlight">Concepts You&#39;ll Master</a></li><li><a href="#landmark-systems" class="table-of-contents__link toc-highlight">Landmark Systems</a></li></ul></li><li><a href="#hardware-requirements" class="table-of-contents__link toc-highlight">Hardware Requirements</a><ul><li><a href="#for-inference" class="table-of-contents__link toc-highlight">For Inference</a></li><li><a href="#for-trainingfine-tuning" class="table-of-contents__link toc-highlight">For Training/Fine-tuning</a></li></ul></li><li><a href="#getting-started-checklist" class="table-of-contents__link toc-highlight">Getting Started Checklist</a><ul><li><a href="#quick-environment-setup" class="table-of-contents__link toc-highlight">Quick Environment Setup</a></li></ul></li><li><a href="#summary" class="table-of-contents__link toc-highlight">Summary</a></li><li><a href="#further-reading" class="table-of-contents__link toc-highlight">Further Reading</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-robotics-book/docs/intro/">Tutorial</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://stackoverflow.com/questions/tagged/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Stack Overflow<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://discordapp.com/invite/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://x.com/docusaurus" target="_blank" rel="noopener noreferrer" class="footer__link-item">X<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/physical-ai-robotics-book/blog/">Blog</a></li><li class="footer__item"><a href="https://github.com/fun33333/physical-ai-robotics-book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Physical AI & Humanoid Robotics Book, Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>